{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "CLEAN_DATA_DIR = \"../data/clean/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfilled  = pd.read_csv(os.path.join(CLEAN_DATA_DIR, \"TRAIN_MERGED_UNFILLED.csv\"))\n",
    "train_A = unfilled[[col for col in unfilled.columns if col not in ['hhid']]]\n",
    "# the train_set as a result of inner joining with SubjectivePoverty (unfilled data) => ~5300 rows\n",
    "\n",
    "subjects_in_train_A = set(train_A['psu_hh_idcode'])\n",
    "filled = pd.read_csv(os.path.join(CLEAN_DATA_DIR, \"TRAIN_MERGED_FILLED.csv\")) # all training data that doesn't appear in unfilled data (these are without labels) => ~15000 ish rows?\n",
    "filled = filled[~filled['psu_hh_idcode'].isin(subjects_in_train_A)]\n",
    "filled_X = filled[[col for col in filled.columns if col not in ['hhid', 'rating_filled']]]\n",
    "train_B = filled_X\n",
    "\n",
    "print(\"train_A: \", train_A.shape)\n",
    "display(train_A.head())\n",
    "print(\"train_B: \", train_B.shape)\n",
    "display(train_B.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, log_loss\n",
    "\n",
    "def generate_best_RF_model(train_A):\n",
    "    feature_cols = list(train_A.columns.difference(['psu_hh_idcode', 'hhid', 'subjectivePoverty_rating']))\n",
    "    X = train_A[feature_cols]  \n",
    "    y = train_A['subjectivePoverty_rating']\n",
    "\n",
    "    # Define the parameter grid\n",
    "    params = {\n",
    "        'n_estimators': [100, 200, 500, 700],\n",
    "        'max_features': ['sqrt', 'log2'],\n",
    "        'max_depth': [4, 5, 6],\n",
    "        'min_samples_split': [2, 5, 50],\n",
    "        'min_samples_leaf': [35, 42, 50],\n",
    "    }\n",
    "\n",
    "    # Create the scorer\n",
    "    log_loss_scorer = make_scorer(log_loss, greater_is_better=False, needs_proba=True)\n",
    "\n",
    "    # Initialize GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=RandomForestClassifier(),\n",
    "        param_grid=params,\n",
    "        scoring=log_loss_scorer,\n",
    "        cv=5,\n",
    "        return_train_score=True\n",
    "    )\n",
    "\n",
    "    # Fit the grid search\n",
    "    grid_search.fit(X, y)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    # Return the best model\n",
    "    return best_model\n",
    "\n",
    "def predict_ratings_RF(model, data):\n",
    "    test_input_x = data.drop(columns=['psu_hh_idcode'])\n",
    "\n",
    "    id = data['psu_hh_idcode']\n",
    "    y_val_pred_proba = model.predict_proba(test_input_x)\n",
    "\n",
    "    column_names = [f\"subjective_poverty_{i}\" for i in range(1, 11)]\n",
    "    probs = pd.DataFrame(y_val_pred_proba, columns=column_names)\n",
    "    pred = pd.concat([id, probs], axis=1)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "def generate_best_XGB_model(train_data):\n",
    "\n",
    "    X_train = train_data.drop(columns=['psu_hh_idcode', 'subjectivePoverty_rating'], axis='columns')\n",
    "    y_train = train_data['subjectivePoverty_rating'] - 1\n",
    "    param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [1, 3, 5],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'subsample': [0.3, 0.5, 0.7],\n",
    "    'colsample_bytree': [0.4, 0.6, 0.8]\n",
    "    }\n",
    "\n",
    "    # Create the XGBoost model\n",
    "    xgb_model = xgb.XGBClassifier(objective='multi:softprob', eval_metric='mlogloss', random_state=101)\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=xgb_model,\n",
    "        param_grid=param_grid,\n",
    "        scoring='neg_log_loss',  # Use log loss as the evaluation metric\n",
    "        cv=5,                    \n",
    "        verbose=1,               \n",
    "        n_jobs=-1                \n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    #print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    #print(\"Best Log Loss Score:\", -grid_search.best_score_)\n",
    "\n",
    "    best_model_xgb = grid_search.best_estimator_\n",
    "    return best_model_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "def predict_ratings_RF(model, train_B_X):\n",
    "    test_ids = train_B_X['psu_hh_idcode']\n",
    "    train_B_X = train_B_X.drop(columns=['psu_hh_idcode'])\n",
    "    preds_proba = model.predict_proba(train_B_X)\n",
    "    output_df = pd.DataFrame(preds_proba, columns=[f'subjective_poverty_{i+1}' for i in range(preds_proba.shape[1])])\n",
    "    output_df.insert(0, 'psu_hh_idcode', test_ids.values)  # Insert the ID column at the start\n",
    "    return output_df\n",
    "\n",
    "def predict_ratings_XGB(model, train_B_X):\n",
    "    test_ids = train_B_X['psu_hh_idcode']\n",
    "    train_B_X = train_B_X.drop(columns=['psu_hh_idcode'])\n",
    "    preds_proba = model.predict_proba(train_B_X)\n",
    "    output_df = pd.DataFrame(preds_proba, columns=[f'subjective_poverty_{i+1}' for i in range(preds_proba.shape[1])])\n",
    "    output_df.insert(0, 'psu_hh_idcode', test_ids.values)  # Insert the ID column at the start\n",
    "    return output_df\n",
    "\n",
    "def predict_ratings_SVM(model, train_B_X):\n",
    "    test_ids = train_B_X['psu_hh_idcode']\n",
    "    train_B_X = train_B_X.drop(columns=['psu_hh_idcode'])\n",
    "    preds_proba = model.predict_proba(train_B_X)\n",
    "\n",
    "    # Identify categorical columns\n",
    "    missing_columns = [col for col in train_B_X.columns if -1 in train_B_X[col].unique()]\n",
    "    \n",
    "    # One-hot encode categorical columns\n",
    "    encoder = OneHotEncoder(sparse_output=False, drop=None)\n",
    "    encoded = encoder.fit_transform(train_B_X[missing_columns])\n",
    "\n",
    "    # Convert to DataFrame and combine with numerical features\n",
    "    encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(missing_columns))\n",
    "    numerical_df = train_B_X.drop(columns=missing_columns)\n",
    "\n",
    "    # Combine numerical and encoded categorical data\n",
    "    processed_train_B_X = pd.concat([numerical_df, encoded_df], axis=1)\n",
    "    scaler = StandardScaler()\n",
    "    train_B_X_scaled = scaler.transform(processed_train_B_X)\n",
    "    preds_prob = model.predict_proba(train_B_X_scaled)\n",
    "    output_df = output_df = pd.DataFrame(preds_proba, columns=[f'subjective_poverty_{i+1}' for i in range(preds_proba.shape[1])])\n",
    "    output_df.insert(0, 'psu_hh_idcode', test_ids.values)  # Insert the ID column at the start\n",
    "    return output_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train_A and train_B\n",
    "train_data = pd.read_csv(os.path.join(CLEAN_DATA_DIR, \"TRAIN_MERGED_FILLED.csv\"))\n",
    "train_A, train_B = train_test_split(train_data, test_size=0.25, stratify=train_data['subjectivePoverty_rating'], random_state=42)\n",
    "\n",
    "train_A.to_csv(os.path.join(CLEAN_DATA_DIR, \"TRAIN_A.csv\"), index=False)\n",
    "train_B.to_csv(os.path.join(CLEAN_DATA_DIR, \"TRAIN_B.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = generate_best_RF_model(train_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n"
     ]
    }
   ],
   "source": [
    "model_xgb = generate_best_XGB_model(train_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb_backup = model_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_B_X = train_B.drop(columns=['subjectivePoverty_rating'])\n",
    "P_XGB = predict_ratings_XGB(model_xgb, train_B_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_XGB.to_csv(os.path.join(\"../data/train_B_preds/train_B_preds_xgb.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# LEARNING weights with training data:\n",
    "#   For each learner:\n",
    "    # train the learner on train_A\n",
    "    # predict probabilities for train_B\n",
    "\n",
    "train_data = pd.read_csv(os.path.join(CLEAN_DATA_DIR, \"TRAIN_MERGED_FILLED.csv\"))\n",
    "train_A, train_B = train_test_split(train_data, test_size=0.25, stratify=train_data['subjectivePoverty_rating'], random_state=42)\n",
    "\n",
    "# Train base learners on train_A\n",
    "model_rf = generate_best_RF_model(train_A)\n",
    "model_xgb = generate_best_XGB_model(train_A)\n",
    "model_svm = generate_best_SVM_model(train_A)\n",
    "\n",
    "\n",
    "ids = train_B['psu_hh_idcode']\n",
    "train_B_X = train_B.drop(columns=['subjectivePoverty_rating'])\n",
    "\n",
    "# predict ratings for train_B \n",
    "\n",
    "P_RF = predict_ratings_RF(model_rf, train_B_X) # returns dataframe containing id,subjective_poverty_1, ...,subjective_poverty_10\n",
    "P_XGB = predict_ratings_XGB(model_xgb, train_B_X)\n",
    "P_SVM = pd.read_csv(\"../data/model_result/train_B_predictions_svm.csv\") # predict_ratings_SVM(model_svm, train_B_X)\n",
    "\n",
    "# aligned on id column. make sure each row corresponds to the same subject\n",
    "assert all(P_RF['psu_hh_idcode'] == P_XGB['psu_hh_idcode'])\n",
    "assert all(P_XGB['psu_hh_idcode'] == P_SVM['psu_hh_idcode'])\n",
    "\n",
    "# logistic regression on probabilities of each learner on train_B\n",
    "X_stack = pd.concat([\n",
    "    P_RF.drop(columns=['psu_hh_idcode']),\n",
    "    P_XGB.drop(columns=['psu_hh_idcode']), \n",
    "    P_SVM.drop(columns=['psu_hh_idcode'])\n",
    "    ], axis=1)\n",
    "\n",
    "y_stack = train_B['subjectivePoverty_rating']\n",
    "stack_model = LogisticRegression(multi_class='multinomial', max_iter=1000)\n",
    "stack_model.fit(X_stack, y_stack)\n",
    "\n",
    "final_predictions = stack_model.predict(X_stack)\n",
    "final_probabilities = stack_model.predict_proba(X_stack)\n",
    "log_loss_score = log_loss(y_stack, final_probabilities)\n",
    "print(f\"Log Loss from Train_B labels: {log_loss_score:.4f}\")\n",
    "\n",
    "# At this point, we have our stacked model which we can use to generate predictions for our test set.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have the three files:\n",
    "- train_B_preds_xgb.csv\n",
    "- train_B_preds_rf.csv\n",
    "- train_B_preds_svm.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_RF = pd.read_csv(\"../data/train_B_preds/train_B_preds_rf.csv\")\n",
    "P_XGB = pd.read_csv(\"../data/train_B_preds/train_B_preds_xgb.csv\")\n",
    "P_SVM = pd.read_csv(\"../data/train_B_preds/train_B_preds_svm.csv\")\n",
    "\n",
    "# aligned on id column. make sure each row corresponds to the same subject\n",
    "assert all(P_RF['psu_hh_idcode'] == P_XGB['psu_hh_idcode'])\n",
    "assert all(P_XGB['psu_hh_idcode'] == P_SVM['psu_hh_idcode'])\n",
    "\n",
    "# logistic regression on probabilities of each learner on train_B\n",
    "X_stack = pd.concat([\n",
    "    P_RF.drop(columns=['psu_hh_idcode']),\n",
    "    P_XGB.drop(columns=['psu_hh_idcode']), \n",
    "    P_SVM.drop(columns=['psu_hh_idcode'])\n",
    "    ], axis=1)\n",
    "\n",
    "y_stack = train_B['subjectivePoverty_rating']\n",
    "stack_model = LogisticRegression(multi_class='multinomial', max_iter=1000)\n",
    "stack_model.fit(X_stack, y_stack)\n",
    "\n",
    "final_predictions = stack_model.predict(X_stack)\n",
    "final_probabilities = stack_model.predict_proba(X_stack)\n",
    "log_loss_score = log_loss(y_stack, final_probabilities)\n",
    "print(f\"Log Loss from Train_B labels: {log_loss_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(model, test_file_path=os.path.join(CLEAN_DATA_DIR, \"TEST_INPUT.csv\")):\n",
    "    X_test = pd.read_csv(test_file_path)\n",
    "    test_ids = X_test['psu_hh_idcode']\n",
    "    X_test = X_test.drop(columns=['psu_hh_idcode'])      \n",
    "    preds_proba = model.predict_proba(X_test)\n",
    "\n",
    "    # Create the output DataFrame\n",
    "    output_df = pd.DataFrame(preds_proba, columns=[f'subjective_poverty_{i+1}' for i in range(preds_proba.shape[1])])\n",
    "    output_df.insert(0, 'psu_hh_idcode', test_ids.values)  # Insert the ID column at the start\n",
    "    return output_df\n",
    "\n",
    "submission_predictions = generate_predictions(stack_model, os.path.join(CLEAN_DATA_DIR, \"TEST_INPUT.csv\"))\n",
    "submission_predictions.to_csv(os.path.join(\"../data/submissions/\", \"submission_stacked.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
