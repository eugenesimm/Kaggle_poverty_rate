{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "CLEAN_DATA_DIR = \"../data/clean/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_A:  (5334, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psu_hh_idcode</th>\n",
       "      <th>subjectivePoverty_rating</th>\n",
       "      <th>q02</th>\n",
       "      <th>q03</th>\n",
       "      <th>q05</th>\n",
       "      <th>q09</th>\n",
       "      <th>q23</th>\n",
       "      <th>Q01</th>\n",
       "      <th>Q03</th>\n",
       "      <th>Q06</th>\n",
       "      <th>Q07</th>\n",
       "      <th>Q08</th>\n",
       "      <th>Q11</th>\n",
       "      <th>Q19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30_8_1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194_1_2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>224_6_1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>323_10_1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>428_10_1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  psu_hh_idcode  subjectivePoverty_rating  q02  q03  q05  q09  q23  Q01  Q03  \\\n",
       "0        30_8_1                         4    1    1   44    0    0    1    1   \n",
       "1       194_1_2                         1    2    2   48    0    0    1    1   \n",
       "2       224_6_1                         3    1    1   61    0    0    1    1   \n",
       "3      323_10_1                         5    1    1   66    0    0    1    1   \n",
       "4      428_10_1                         4    2    1   72    0    0    1    1   \n",
       "\n",
       "   Q06  Q07  Q08   Q11  Q19  \n",
       "0  2.0  1.0  2.0  13.0  2.0  \n",
       "1  2.0  0.0  2.0  13.0  2.0  \n",
       "2  2.0  0.0  2.0  13.0  2.0  \n",
       "3  2.0  0.0  2.0  13.0  2.0  \n",
       "4  1.0  0.0  2.0  14.0  2.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_B:  (14929, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psu_hh_idcode</th>\n",
       "      <th>q02</th>\n",
       "      <th>q03</th>\n",
       "      <th>q05</th>\n",
       "      <th>q09</th>\n",
       "      <th>q23</th>\n",
       "      <th>Q01</th>\n",
       "      <th>Q03</th>\n",
       "      <th>Q06</th>\n",
       "      <th>Q07</th>\n",
       "      <th>Q08</th>\n",
       "      <th>Q11</th>\n",
       "      <th>Q19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5334</th>\n",
       "      <td>1_2_2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5335</th>\n",
       "      <td>1_3_2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5336</th>\n",
       "      <td>1_3_3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5337</th>\n",
       "      <td>1_5_2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5338</th>\n",
       "      <td>1_5_3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     psu_hh_idcode  q02  q03  q05  q09  q23  Q01  Q03  Q06  Q07  Q08   Q11  \\\n",
       "5334         1_2_2    2    2   47    0    0  1.0  1.0  2.0  1.0  2.0  13.0   \n",
       "5335         1_3_2    2    2   56    0    0  1.0  1.0  2.0  1.0  2.0  13.0   \n",
       "5336         1_3_3    1    4   27    0    2  1.0  1.0  2.0  1.0  2.0  13.0   \n",
       "5337         1_5_2    2    2   49    0    0  1.0  1.0  1.0  0.0  2.0   2.0   \n",
       "5338         1_5_3    1    4   36    0    2  1.0  1.0  2.0  0.0  2.0   2.0   \n",
       "\n",
       "      Q19  \n",
       "5334  2.0  \n",
       "5335  2.0  \n",
       "5336  2.0  \n",
       "5337  2.0  \n",
       "5338  2.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unfilled  = pd.read_csv(os.path.join(CLEAN_DATA_DIR, \"TRAIN_MERGED_UNFILLED.csv\"))\n",
    "train_A = unfilled[[col for col in unfilled.columns if col not in ['hhid']]]\n",
    "# the train_set as a result of inner joining with SubjectivePoverty (unfilled data) => ~5300 rows\n",
    "\n",
    "subjects_in_train_A = set(train_A['psu_hh_idcode'])\n",
    "filled = pd.read_csv(os.path.join(CLEAN_DATA_DIR, \"TRAIN_MERGED_FILLED.csv\")) # all training data that doesn't appear in unfilled data (these are without labels) => ~15000 ish rows?\n",
    "filled = filled[~filled['psu_hh_idcode'].isin(subjects_in_train_A)]\n",
    "filled_X = filled[[col for col in filled.columns if col not in ['hhid', 'rating_filled']]]\n",
    "train_B = filled_X\n",
    "\n",
    "print(\"train_A: \", train_A.shape)\n",
    "display(train_A.head())\n",
    "print(\"train_B: \", train_B.shape)\n",
    "display(train_B.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "# LEARNING weights with training data:\n",
    "#   For each learner:\n",
    "    # train the learner on train_A\n",
    "    # predict probabilities for train_B\n",
    "\n",
    "P_RF = pd.read_csv(file_path_to_p_rf)\n",
    "P_XGB = pd.read_csv(file_path_to_p_xgb)\n",
    "P_SVM = pd.read_csv(file_path_to_p_svm)\n",
    "\n",
    "# aligned on id column. make sure each row corresponds to the same subject\n",
    "assert all(P_RF['psu_hh_idcode'] == P_XGB['psu_hh_idcode'])\n",
    "assert all(P_XGB['psu_hh_idcode'] == P_SVM['psu_hh_idcode'])\n",
    "\n",
    "P_RF = P_RF.drop(columns=['psu_hh_idcode'])\n",
    "P_XGB = P_XGB.drop(columns=['psu_hh_idcode'])\n",
    "P_SVM = P_SVM.drop(columns=['psu_hh_idcode'])\n",
    "\n",
    "\n",
    "# logistic regression on probabilities of each learner on train_B\n",
    "X_stack = pd.concat([P_RF, P_XGB, P_SVM], axis=1)\n",
    "\n",
    "\n",
    "stack_learner = LogisticRegression(multi_class='multinomial', max_iter=1000)\n",
    "stack_learner.fit(X_train, y_train)\n",
    "\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
