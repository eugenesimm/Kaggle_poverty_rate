{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "CLEAN_DATA_DIR = \"../data/clean/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_A:  (5334, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psu_hh_idcode</th>\n",
       "      <th>subjectivePoverty_rating</th>\n",
       "      <th>q02</th>\n",
       "      <th>q03</th>\n",
       "      <th>q05</th>\n",
       "      <th>q09</th>\n",
       "      <th>q23</th>\n",
       "      <th>Q01</th>\n",
       "      <th>Q03</th>\n",
       "      <th>Q06</th>\n",
       "      <th>Q07</th>\n",
       "      <th>Q08</th>\n",
       "      <th>Q11</th>\n",
       "      <th>Q19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30_8_1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194_1_2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>224_6_1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>323_10_1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>428_10_1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  psu_hh_idcode  subjectivePoverty_rating  q02  q03  q05  q09  q23  Q01  Q03  \\\n",
       "0        30_8_1                         4    1    1   44    0    0    1    1   \n",
       "1       194_1_2                         1    2    2   48    0    0    1    1   \n",
       "2       224_6_1                         3    1    1   61    0    0    1    1   \n",
       "3      323_10_1                         5    1    1   66    0    0    1    1   \n",
       "4      428_10_1                         4    2    1   72    0    0    1    1   \n",
       "\n",
       "   Q06  Q07  Q08   Q11  Q19  \n",
       "0  2.0  1.0  2.0  13.0  2.0  \n",
       "1  2.0  0.0  2.0  13.0  2.0  \n",
       "2  2.0  0.0  2.0  13.0  2.0  \n",
       "3  2.0  0.0  2.0  13.0  2.0  \n",
       "4  1.0  0.0  2.0  14.0  2.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_B:  (14929, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psu_hh_idcode</th>\n",
       "      <th>q02</th>\n",
       "      <th>q03</th>\n",
       "      <th>q05</th>\n",
       "      <th>q09</th>\n",
       "      <th>q23</th>\n",
       "      <th>Q01</th>\n",
       "      <th>Q03</th>\n",
       "      <th>Q06</th>\n",
       "      <th>Q07</th>\n",
       "      <th>Q08</th>\n",
       "      <th>Q11</th>\n",
       "      <th>Q19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5334</th>\n",
       "      <td>1_2_2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5335</th>\n",
       "      <td>1_3_2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5336</th>\n",
       "      <td>1_3_3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5337</th>\n",
       "      <td>1_5_2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5338</th>\n",
       "      <td>1_5_3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     psu_hh_idcode  q02  q03  q05  q09  q23  Q01  Q03  Q06  Q07  Q08   Q11  \\\n",
       "5334         1_2_2    2    2   47    0    0  1.0  1.0  2.0  1.0  2.0  13.0   \n",
       "5335         1_3_2    2    2   56    0    0  1.0  1.0  2.0  1.0  2.0  13.0   \n",
       "5336         1_3_3    1    4   27    0    2  1.0  1.0  2.0  1.0  2.0  13.0   \n",
       "5337         1_5_2    2    2   49    0    0  1.0  1.0  1.0  0.0  2.0   2.0   \n",
       "5338         1_5_3    1    4   36    0    2  1.0  1.0  2.0  0.0  2.0   2.0   \n",
       "\n",
       "      Q19  \n",
       "5334  2.0  \n",
       "5335  2.0  \n",
       "5336  2.0  \n",
       "5337  2.0  \n",
       "5338  2.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unfilled  = pd.read_csv(os.path.join(CLEAN_DATA_DIR, \"TRAIN_MERGED_UNFILLED.csv\"))\n",
    "train_A = unfilled[[col for col in unfilled.columns if col not in ['hhid']]]\n",
    "# the train_set as a result of inner joining with SubjectivePoverty (unfilled data) => ~5300 rows\n",
    "\n",
    "subjects_in_train_A = set(train_A['psu_hh_idcode'])\n",
    "filled = pd.read_csv(os.path.join(CLEAN_DATA_DIR, \"TRAIN_MERGED_FILLED.csv\")) # all training data that doesn't appear in unfilled data (these are without labels) => ~15000 ish rows?\n",
    "filled = filled[~filled['psu_hh_idcode'].isin(subjects_in_train_A)]\n",
    "filled_X = filled[[col for col in filled.columns if col not in ['hhid', 'rating_filled']]]\n",
    "train_B = filled_X\n",
    "\n",
    "print(\"train_A: \", train_A.shape)\n",
    "display(train_A.head())\n",
    "print(\"train_B: \", train_B.shape)\n",
    "display(train_B.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# LEARNING weights with training data:\n",
    "#   For each learner:\n",
    "    # train the learner on train_A\n",
    "    # predict probabilities for train_B\n",
    "\n",
    "train_data = pd.read_csv(os.path.join(CLEAN_DATA_DIR, \"TRAIN_MERGED_FILLED.csv\"))\n",
    "train_A, train_B = train_test_split(train_data, test_size=0.25, stratify=train_data['subjectivePoverty_rating'], random_state=42)\n",
    "\n",
    "# Train base learners on train_A\n",
    "model_rf = generate_best_RF_model(train_A)\n",
    "model_xgb = generate_best_XGB_model(train_A)\n",
    "model_svm = generate_best_SVM_model(train_A)\n",
    "\n",
    "\n",
    "ids = train_B['psu_hh_idcode']\n",
    "train_B_X = train_B.drop(columns=['subjectivePoverty_rating'])\n",
    "\n",
    "# predict ratings for train_B \n",
    "P_RF = predict_ratings_RF(model_rf, train_B_X) # returns dataframe containing id,subjective_poverty_1, ...,subjective_poverty_10\n",
    "P_XGB = predict_ratings_XGB(model_xgb, train_B_X)\n",
    "P_SVM = predict_ratings_SVM(model_svm, train_B_X)\n",
    "\n",
    "# aligned on id column. make sure each row corresponds to the same subject\n",
    "assert all(P_RF['psu_hh_idcode'] == P_XGB['psu_hh_idcode'])\n",
    "assert all(P_XGB['psu_hh_idcode'] == P_SVM['psu_hh_idcode'])\n",
    "\n",
    "\n",
    "P_RF = P_RF.drop(columns=['psu_hh_idcode'])\n",
    "P_XGB = P_XGB.drop(columns=['psu_hh_idcode'])\n",
    "P_SVM = P_SVM.drop(columns=['psu_hh_idcode'])\n",
    "\n",
    "\n",
    "# logistic regression on probabilities of each learner on train_B\n",
    "X_stack = pd.concat([\n",
    "    P_RF.drop(columns=['psu_hh_idcode']),\n",
    "    P_XGB.drop(columns=['psu_hh_idcode']), \n",
    "    P_SVM.drop(columns=['psu_hh_idcode'])\n",
    "    ], axis=1)\n",
    "\n",
    "y_stack = train_B['subjectivePoverty_rating']\n",
    "stack_model = LogisticRegression(multi_class='multinomial', max_iter=1000)\n",
    "stack_model.fit(X_stack, y_stack)\n",
    "\n",
    "final_predictions = stack_model.predict(X_stack)\n",
    "final_probabilities = stack_model.predict_proba(X_stack)\n",
    "log_loss_score = log_loss(y_stack, final_probabilities)\n",
    "print(f\"Log Loss from Train_B labels: {log_loss_score:.4f}\")\n",
    "\n",
    "# At this point, we have our stacked model which we can use to generate predictions for our test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(model, test_file_path=os.path.join(CLEAN_DATA_DIR, \"TEST_INPUT.csv\")):\n",
    "    X_test = pd.read_csv(test_file_path)\n",
    "    test_ids = X_test['psu_hh_idcode']\n",
    "    X_test = X_test.drop(columns=['psu_hh_idcode'])      \n",
    "    preds_proba = model.predict_proba(X_test)\n",
    "\n",
    "    # Create the output DataFrame\n",
    "    output_df = pd.DataFrame(preds_proba, columns=[f'subjective_poverty_{i+1}' for i in range(preds_proba.shape[1])])\n",
    "    output_df.insert(0, 'psu_hh_idcode', test_ids.values)  # Insert the ID column at the start\n",
    "    return output_df\n",
    "\n",
    "submission_predictions = generate_predictions(stack_model, os.path.join(CLEAN_DATA_DIR, \"TEST_INPUT.csv\"))\n",
    "submission_predictions.to_csv(os.path.join(\"../data/submissions/\", \"submission_stacked.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
