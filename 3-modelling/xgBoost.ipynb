{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os \n",
    "\n",
    "CLEAN_DATA_DIR = \"../data/clean/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psu_hh_idcode</th>\n",
       "      <th>hhid</th>\n",
       "      <th>rating_filled</th>\n",
       "      <th>q02</th>\n",
       "      <th>q03</th>\n",
       "      <th>q05</th>\n",
       "      <th>q09</th>\n",
       "      <th>q23</th>\n",
       "      <th>Q01</th>\n",
       "      <th>Q03</th>\n",
       "      <th>Q06</th>\n",
       "      <th>Q07</th>\n",
       "      <th>Q08</th>\n",
       "      <th>Q11</th>\n",
       "      <th>Q19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30_8_1</td>\n",
       "      <td>3008</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194_1_2</td>\n",
       "      <td>19401</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>224_6_1</td>\n",
       "      <td>22406</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>323_10_1</td>\n",
       "      <td>32310</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>428_10_1</td>\n",
       "      <td>42810</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  psu_hh_idcode   hhid  rating_filled  q02  q03  q05  q09  q23  Q01  Q03  Q06  \\\n",
       "0        30_8_1   3008            4.0    1    1   44    0    0  1.0  1.0  2.0   \n",
       "1       194_1_2  19401            1.0    2    2   48    0    0  1.0  1.0  2.0   \n",
       "2       224_6_1  22406            3.0    1    1   61    0    0  1.0  1.0  2.0   \n",
       "3      323_10_1  32310            5.0    1    1   66    0    0  1.0  1.0  2.0   \n",
       "4      428_10_1  42810            4.0    2    1   72    0    0  1.0  1.0  1.0   \n",
       "\n",
       "   Q07  Q08   Q11  Q19  \n",
       "0  1.0  2.0  13.0  2.0  \n",
       "1  0.0  2.0  13.0  2.0  \n",
       "2  0.0  2.0  13.0  2.0  \n",
       "3  0.0  2.0  13.0  2.0  \n",
       "4  0.0  2.0  14.0  2.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join(CLEAN_DATA_DIR, \"TRAIN_MERGED_FILLED.csv\"))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss from test: 1.9346025316905149\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "data = pd.read_csv(os.path.join(CLEAN_DATA_DIR, \"TRAIN_MERGED_FILLED.csv\"))\n",
    "X_train, _, y_train, _ = train_test_split(data.drop(['psu_hh_idcode', 'hhid', 'rating_filled'], axis='columns'), data['rating_filled'], test_size=0.2, random_state=101)\n",
    "\n",
    "unfilled_data = pd.read_csv(os.path.join(CLEAN_DATA_DIR, \"TRAIN_MERGED_UNFILLED.csv\"))\n",
    "X_test = unfilled_data.drop(['psu_hh_idcode', 'hhid', 'subjectivePoverty_rating'], axis='columns')\n",
    "y_test = unfilled_data['subjectivePoverty_rating']\n",
    "\n",
    "# for some reason xgb requires the labels to begin at 0 instead of 1 so we will shift down by 1\n",
    "y_train = y_train - 1\n",
    "y_test = y_test - 1\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective='multiclass:softprob', eval_metric='mlogloss', learning_rate=0.1, max_depth=1)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "preds = xgb_model.predict(X_test)\n",
    "preds_proba = xgb_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "print(f\"Log Loss from test: {log_loss(y_test, preds_proba)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [1, 3, 5],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Create the XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softprob', eval_metric='mlogloss', random_state=101)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_log_loss',  # Use log loss as the evaluation metric\n",
    "    cv=3,                    # 3-fold cross-validation\n",
    "    verbose=2,               # Print progress\n",
    "    n_jobs=-1                # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best log loss score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Log Loss Score:\", -grid_search.best_score_)\n",
    "\n",
    "# Use the best model to make predictions\n",
    "best_model = grid_search.best_estimator_\n",
    "preds_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "# Evaluate log loss on the test data\n",
    "from sklearn.metrics import log_loss\n",
    "print(f\"Log Loss from test: {log_loss(y_test, preds_proba)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline log loss = $-log(\\frac{1}{\\#classes}) = -log(\\frac{1}{10}) = 2.303$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique values in test classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "unique values in predicted classes: [2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "print(\"unique values in test classes:\", sorted(list(y_test.unique())))\n",
    "print(\"unique values in predicted classes:\", sorted(list(np.unique(preds))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
