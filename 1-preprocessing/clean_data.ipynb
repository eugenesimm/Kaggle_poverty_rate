{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "RAW_DATA_DIR = \"../data/raw/\"\n",
    "CLEAN_DATA_DIR = \"../data/clean/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Cleaning\n",
    "- column name formatting\n",
    "- generating primary key psu_hh_idcode\n",
    "- removing columns with high NA rates with threshold\n",
    "- removing columns with multi-colinearity\n",
    "- mapping binary responses to 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_education(path=os.path.join(RAW_DATA_DIR, \"train_Education.csv\")): \n",
    "    Education = pd.read_csv(path)\n",
    "    Education['psu_hh_idcode'] = Education['psu'].astype(str) + '_' + Education['hh'].astype(str) + '_' + Education['idcode'].astype(str)\n",
    "    Education.drop(columns=['psu', 'hh', 'idcode'], inplace=True)\n",
    "    Education = Education[['psu_hh_idcode'] + [col for col in Education.columns if col != 'psu_hh_idcode']]\n",
    "    Education.columns = [col.capitalize() if col.lower().startswith('q') else col for col in Education.columns]\n",
    "    print(\"Initial Education training set:\")\n",
    "    display(Education.head(3))\n",
    "    return Education\n",
    "\n",
    "def import_house(path=os.path.join(RAW_DATA_DIR, \"train_HouseholdInfo.csv\")):\n",
    "    HouseholdInfo = pd.read_csv(path)\n",
    "    HouseholdInfo['psu_hh_idcode'] = HouseholdInfo['psu'].astype(str) + '_' + HouseholdInfo['hh'].astype(str) + '_' + HouseholdInfo['idcode'].astype(str)\n",
    "    HouseholdInfo = HouseholdInfo[['psu_hh_idcode'] + [col for col in HouseholdInfo.columns if col != 'psu_hh_idcode']]\n",
    "    HouseholdInfo.drop(columns=['psu', 'idcode', 'hh'], inplace=True)\n",
    "    print(\"Initial HouseholdInfo training set:\")\n",
    "    display(HouseholdInfo.head(3))\n",
    "    return HouseholdInfo\n",
    "\n",
    "def remove_cols_high_na(df, threshold=0.3):\n",
    "    # NA rate\n",
    "    na_counts = df.isna().sum()\n",
    "    nrow = len(df)\n",
    "    na_rate = na_counts / nrow\n",
    "    na_rate = na_rate.sort_values(ascending=False)\n",
    "    cols_to_drop = na_rate[na_rate > threshold] # default threshold = 30%\n",
    "    print(f\"=> Removed {len(cols_to_drop)} Columns from Education due to NA rates above threshold={threshold*100}%\\n\")\n",
    "    display(list(cols_to_drop.index))\n",
    "\n",
    "    df = df.drop(columns=cols_to_drop.index)\n",
    "    print(\"Education after dropping columns with high NA rate:\")\n",
    "    display(df.head(3))\n",
    "    return df\n",
    "\n",
    "def correlational_matrix_heatmap(data, fig_size=(6,6), cols_to_exclude=[]):\n",
    "    data_variates = data.drop(columns=cols_to_exclude)\n",
    "    cor_matrix = data_variates.corr()\n",
    "    \n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=fig_size)\n",
    "    ax = sns.heatmap(cor_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", cbar=False)\n",
    "\n",
    "    # Move x-axis labels to the top\n",
    "    ax.xaxis.tick_top()  # Moves x-axis labels to the top\n",
    "    ax.xaxis.set_label_position('top')  # Sets the label position to the top\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def categorical_encoder(data, col, range_of_values, fill_na=np.nan):\n",
    "    col_index = data.columns.get_loc(col)\n",
    "\n",
    "    # One-hot encode the specified categorical column\n",
    "    encoder = OneHotEncoder(categories=[range_of_values], sparse_output=False, handle_unknown='ignore')\n",
    "    encoded = encoder.fit_transform(data[[col]])  # Fix: Ensure data[[col]] is used as input\n",
    "\n",
    "    # Convert to DataFrame with correct column names\n",
    "    encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out([col]), index=data.index)\n",
    "\n",
    "    # Rename columns to remove '.0' suffix if present\n",
    "    encoded_df.columns = [name.replace('.0', '') for name in encoded_df.columns]\n",
    "\n",
    "    # Fill in missing values as 0\n",
    "    encoded_df[data[col].isna()] = 0\n",
    "\n",
    "    # Drop the original column and combine with the encoded columns\n",
    "    return_df = data.drop(columns=[col])\n",
    "    for i, encoded_col in enumerate(encoded_df.columns):\n",
    "        return_df.insert(col_index + i, encoded_col, encoded_df[encoded_col])\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning HouseholdInfo Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial HouseholdInfo training set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psu_hh_idcode</th>\n",
       "      <th>hhid</th>\n",
       "      <th>q02</th>\n",
       "      <th>q03</th>\n",
       "      <th>q04</th>\n",
       "      <th>q05y</th>\n",
       "      <th>q05m</th>\n",
       "      <th>q06</th>\n",
       "      <th>q07</th>\n",
       "      <th>q08</th>\n",
       "      <th>...</th>\n",
       "      <th>q13</th>\n",
       "      <th>q14</th>\n",
       "      <th>q15</th>\n",
       "      <th>q16</th>\n",
       "      <th>q17</th>\n",
       "      <th>q18</th>\n",
       "      <th>q19</th>\n",
       "      <th>q20</th>\n",
       "      <th>q21</th>\n",
       "      <th>q22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_2_1</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19600711</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_2_2</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>19650225</td>\n",
       "      <td>47</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_3_1</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19540203</td>\n",
       "      <td>58</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  psu_hh_idcode  hhid  q02  q03       q04  q05y  q05m  q06  q07  q08  ...  \\\n",
       "0         1_2_1   102    1    1  19600711    52     1  1.0  1.0  2.0  ...   \n",
       "1         1_2_2   102    2    2  19650225    47     6  1.0  1.0  1.0  ...   \n",
       "2         1_3_1   103    1    1  19540203    58     7  1.0  1.0  2.0  ...   \n",
       "\n",
       "   q13  q14   q15  q16  q17  q18  q19  q20   q21  q22  \n",
       "0  3.0  2.0  80.0  NaN    2  NaN  3.0  2.0  80.0  NaN  \n",
       "1  3.0  2.0  67.0  NaN    2  NaN  3.0  2.0  74.0  NaN  \n",
       "2  2.0  2.0  85.0  NaN    2  NaN  2.0  2.0  67.0  NaN  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HouseholdInfo after dropping columns with high correlations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psu_hh_idcode</th>\n",
       "      <th>hhid</th>\n",
       "      <th>q02</th>\n",
       "      <th>q03_1</th>\n",
       "      <th>q03_2</th>\n",
       "      <th>q03_3</th>\n",
       "      <th>q03_4</th>\n",
       "      <th>q03_5</th>\n",
       "      <th>q03_6</th>\n",
       "      <th>q03_7</th>\n",
       "      <th>q03_8</th>\n",
       "      <th>q03_9</th>\n",
       "      <th>q03_10</th>\n",
       "      <th>q03_11</th>\n",
       "      <th>q03_12</th>\n",
       "      <th>q03_13</th>\n",
       "      <th>q03_14</th>\n",
       "      <th>q05</th>\n",
       "      <th>q09</th>\n",
       "      <th>q23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_2_1</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_2_2</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_3_1</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  psu_hh_idcode  hhid  q02  q03_1  q03_2  q03_3  q03_4  q03_5  q03_6  q03_7  \\\n",
       "0         1_2_1   102    1    1.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1         1_2_2   102    2    0.0    1.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2         1_3_1   103    1    1.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   q03_8  q03_9  q03_10  q03_11  q03_12  q03_13  q03_14  q05  q09  q23  \n",
       "0    0.0    0.0     0.0     0.0     0.0     0.0     0.0   52    0    0  \n",
       "1    0.0    0.0     0.0     0.0     0.0     0.0     0.0   47    0    0  \n",
       "2    0.0    0.0     0.0     0.0     0.0     0.0     0.0   58    0    0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(24001, 20)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_train = import_house(path=os.path.join(RAW_DATA_DIR, \"train_HouseholdInfo.csv\"))\n",
    "\n",
    "def clean_house(house_train):\n",
    "    house_train = house_train.drop(columns=['q22','q16','q15','q21','q18','q12','q08','q07','q13','q14','q20','q19','q06'])\n",
    "    #remove_cols_high_na(house_train, threshold=0.1)\n",
    "\n",
    "    # Basic cleaning\n",
    "    house_train.drop(columns=['q04'], inplace=True) # dropping q04 because date of birth is unnecessary when we have age\n",
    "    house_train['q05'] = house_train['q05y'] # age is just in years, not years,months\n",
    "    house_train.drop(columns=['q05y', 'q05m'], inplace=True)\n",
    "\n",
    "    # print(\"Correlation Matrix to check Multi-colinearity\")\n",
    "    # correlational_matrix_heatmap(house_train, fig_size=(6,6), cols_to_exclude=['psu_hh_idcode', 'hhid'])\n",
    "\n",
    "    # AFTER CORRELATION ANALYSIS\n",
    "    house_train.drop(columns=['q10'], inplace=True) # q10 has 0 variance, its not very useful as an explanatory variable. get rid of it\n",
    "\n",
    "    # Map binary responses to 1 (yes) or 0 (no)\n",
    "    house_train['q11'] = house_train['q11'].map({1: 'Yes', 2: 'No'}).map({'Yes': 1, 'No': 0})\n",
    "\n",
    "    house_train['q17'] = house_train['q17'].map({1: 'Yes', 2: 'No'}).map({'Yes': 1, 'No': 0})\n",
    "\n",
    "    # q11 and q17 seems to be highly correlated so we decided to combine the two\n",
    "    house_train['q23'] = house_train['q11'] + house_train['q17']\n",
    "    house_train.drop(columns=['q11', 'q17'], inplace=True)\n",
    "    \n",
    "    # Sort columns order\n",
    "    house_train = house_train[['psu_hh_idcode', 'hhid'] + [col for col in sorted(house_train.columns) if col not in ['psu_hh_idcode', 'hhid']]]\n",
    "\n",
    "    # one-hot-encoding\n",
    "    house_train = categorical_encoder(house_train, 'q03', range_of_values=list(range(1,15)), fill_na=0)\n",
    "\n",
    "    print(\"HouseholdInfo after dropping columns with high correlations\")\n",
    "    display(house_train.head(3))\n",
    "    return house_train\n",
    "\n",
    "house_train = clean_house(house_train)\n",
    "# correlational_matrix_heatmap(house_train, fig_size=(6,6), cols_to_exclude=['psu_hh_idcode', 'hhid'])\n",
    "\n",
    "# Output to CSV\n",
    "house_train.to_csv(os.path.join(CLEAN_DATA_DIR, \"train_HouseholdInfo_clean_oh_encoded.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Education Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Education training set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psu_hh_idcode</th>\n",
       "      <th>Q01</th>\n",
       "      <th>Q02</th>\n",
       "      <th>Q03</th>\n",
       "      <th>Q04</th>\n",
       "      <th>Q05</th>\n",
       "      <th>Q06</th>\n",
       "      <th>Q07</th>\n",
       "      <th>Q08</th>\n",
       "      <th>Q09</th>\n",
       "      <th>...</th>\n",
       "      <th>Q57</th>\n",
       "      <th>Q58</th>\n",
       "      <th>Q59</th>\n",
       "      <th>Q60</th>\n",
       "      <th>Q61</th>\n",
       "      <th>Q62</th>\n",
       "      <th>Q63</th>\n",
       "      <th>Q64</th>\n",
       "      <th>Q65</th>\n",
       "      <th>Q66</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2_8_3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3_8_4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6_5_3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  psu_hh_idcode  Q01  Q02  Q03  Q04  Q05  Q06  Q07  Q08  Q09  ...  Q57  Q58  \\\n",
       "0         2_8_3    1    1    1  2.0  3.0  3.0  2.0  1.0  1.0  ...  2.0  NaN   \n",
       "1         3_8_4    1    1    1  2.0  2.0  2.0  0.0  1.0  1.0  ...  2.0  NaN   \n",
       "2         6_5_3    1    1    1  2.0  3.0  3.0  0.0  1.0  1.0  ...  2.0  NaN   \n",
       "\n",
       "   Q59  Q60  Q61  Q62  Q63  Q64  Q65  Q66  \n",
       "0  2.0  NaN  2.0  NaN  NaN  2.0  NaN  2.0  \n",
       "1  2.0  NaN  2.0  NaN  NaN  2.0  NaN  2.0  \n",
       "2  2.0  NaN  2.0  NaN  NaN  2.0  NaN  4.0  \n",
       "\n",
       "[3 rows x 67 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Columns to remove due to high correlation with another variate ['Q02', 'Q04', 'Q05', 'Q14', 'Q17', 'Q18']\n",
      "Education after dropping columns with high correlations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psu_hh_idcode</th>\n",
       "      <th>Q01</th>\n",
       "      <th>Q03</th>\n",
       "      <th>Q06</th>\n",
       "      <th>Q07</th>\n",
       "      <th>Q08</th>\n",
       "      <th>Q11</th>\n",
       "      <th>Q19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2_8_3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3_8_4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6_5_3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  psu_hh_idcode  Q01  Q03  Q06  Q07  Q08  Q11  Q19\n",
       "0         2_8_3    1    1  3.0  2.0  1.0  NaN  NaN\n",
       "1         3_8_4    1    1  2.0  0.0  1.0  NaN  NaN\n",
       "2         6_5_3    1    1  3.0  0.0  1.0  NaN  NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(22406, 22)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edu_train = import_education(path=os.path.join(RAW_DATA_DIR, \"train_Education.csv\"))\n",
    "def clean_edu(edu_train):\n",
    "    edu_train = edu_train.drop(columns=['Q60','Q31','Q16','Q10','Q65','Q63','Q62','Q55','Q56',\n",
    " 'Q52','Q53','Q51','Q54','Q58','Q20','Q49','Q44','Q25','Q30','Q29',\n",
    " 'Q48','Q47','Q36','Q37','Q39','Q38','Q34','Q40','Q35','Q33','Q13',\n",
    " 'Q12','Q09','Q28','Q27','Q32','Q26','Q50','Q57','Q59','Q61','Q64',\n",
    " 'Q46','Q45','Q66','Q43','Q21','Q41','Q42','Q24','Q23','Q22','Q15'])\n",
    "\n",
    "    #remove_cols_high_na(edu_train, threshold=0.3)\n",
    "    # print(\"Correlation Matrix to check Multi-colinearity\")\n",
    "    #correlational_matrix_heatmap(edu_train, fig_size=(8,8), cols_to_exclude='psu_hh_idcode')\n",
    "\n",
    "    cols_to_drop_multicolinear = ['Q02', 'Q04', 'Q05', 'Q14', 'Q17', 'Q18']\n",
    "    edu_train.drop(columns=cols_to_drop_multicolinear, inplace=True)\n",
    "    print(\"=> Columns to remove due to high correlation with another variate\", cols_to_drop_multicolinear)\n",
    "\n",
    "    print(\"Education after dropping columns with high correlations\")\n",
    "    display(edu_train.head(3))\n",
    "\n",
    "    edu_train = edu_train[['psu_hh_idcode'] + [col for col in sorted(edu_train.columns) if col not in ['psu_hh_idcode']]]\n",
    "\n",
    "    # mapping values\n",
    "    edu_train['Q01'] = edu_train['Q01'].map({1: \"yes, easily\", 2: \"yes, with difficulty\", 3: \"no\"}).map({\"yes, easily\": 2, \"yes, with difficulty\": 1, \"no\": 0})\n",
    "    edu_train['Q03'] = edu_train['Q03'].map({1: \"yes\", 2: \"no\"}).map({\"yes\": 1, \"no\": 0})\n",
    "    edu_train['Q08'] = edu_train['Q08'].map({1: \"yes\", 2: \"no\"}).map({\"yes\": 1, \"no\": 1})\n",
    "\n",
    "    # missing values\n",
    "    edu_train['Q06'] = edu_train['Q06'].fillna(0)\n",
    "    edu_train['Q07'] = edu_train['Q07'].fillna(0)\n",
    "    edu_train['Q08'] = edu_train['Q08'].fillna(-1)\n",
    "    \n",
    "    # One-hot-encoding: Q1\n",
    "    edu_train = categorical_encoder(edu_train, 'Q01', range_of_values=[0,1,2], fill_na=0)\n",
    "\n",
    "    # One-hot encoding: Q11\n",
    "    edu_train = categorical_encoder(edu_train, 'Q11', range_of_values=list(range(1,14)), fill_na=0)\n",
    "\n",
    "    return edu_train\n",
    "    \n",
    "\n",
    "edu_train = clean_edu(edu_train)\n",
    "#correlational_matrix_heatmap(edu_train, fig_size=(6,6), cols_to_exclude='psu_hh_idcode')\n",
    "\n",
    "    # Output to CSV\n",
    "edu_train.to_csv(os.path.join(CLEAN_DATA_DIR, \"train_Education_clean_oh_encoded.csv\"), index=False)\n",
    "edu_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SubjectivePoverty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psu_hh_idcode</th>\n",
       "      <th>subjectivePoverty_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30_8_1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194_1_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>224_6_1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  psu_hh_idcode  subjectivePoverty_rating\n",
       "0        30_8_1                         4\n",
       "1       194_1_2                         1\n",
       "2       224_6_1                         3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SubjectivePoverty = pd.read_csv(os.path.join(RAW_DATA_DIR, \"train_SubjectivePoverty.csv\"))\n",
    "subjective_poverty_columns = [f'subjective_poverty_{i}' for i in range(1, 11)]\n",
    "SubjectivePoverty['subjectivePoverty_rating'] = SubjectivePoverty[subjective_poverty_columns].idxmax(axis=1).str.extract('(\\d+)').astype(int)\n",
    "Ratings = SubjectivePoverty[['psu_hh_idcode', 'subjectivePoverty_rating']]\n",
    "\n",
    "# Three of the subjects in SubjectivePoverty train set do not show up in either Education or Household train sets. We get rid of these from subjectivePoverty\n",
    "# Get the IDs from household and education DataFrames\n",
    "household_ids = set(house_train['psu_hh_idcode'])\n",
    "education_ids = set(edu_train['psu_hh_idcode'])\n",
    "valid_ids = household_ids.union(education_ids)\n",
    "# Filter ratings_df to keep only rows with IDs present in valid_ids\n",
    "Ratings = Ratings[Ratings['psu_hh_idcode'].isin(valid_ids)]\n",
    "\n",
    "display(Ratings.head(3))\n",
    "\n",
    "Ratings.to_csv(os.path.join(CLEAN_DATA_DIR, \"train_SubjectivePoverty_clean.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_merged_set(house_df, edu_df, subjective_poverty_df=None, impute_ratings=False, save_to=None):\n",
    "    train_or_test = \"TRAIN\" if subjective_poverty_df is not None else \"TEST\"\n",
    "    filled_or_unfilled = \"UNFILLED\" if impute_ratings is False else \"FILLED\"\n",
    "\n",
    "    if save_to is None:\n",
    "        save_to = f\"../data/model_training/{train_or_test}_{filled_or_unfilled}_encoded.csv\"\n",
    "\n",
    "    X = house_df.merge(edu_df, on='psu_hh_idcode', how='inner')\n",
    "    print(f\"X.shape: {X.shape}\")\n",
    "\n",
    "    # fill in Q19 based on q05\n",
    "    X['Q19'] = X['Q19'].fillna(X['q05'].apply(lambda x: 1 if x is not None and x <= 19 else 0))\n",
    "\n",
    "    if subjective_poverty_df is None:\n",
    "        merged_test_input = X\n",
    "        merged_test_input = merged_test_input[['psu_hh_idcode']+ [col for col in merged_test_input.columns if col not in ['psu_hh_idcode', 'hhid']]]\n",
    "        print(\"TEST_INPUT.csv:\", merged_test_input.shape, f\"=> {merged_test_input.shape[1]-1} features\")\n",
    "        merged_test_input.to_csv(save_to, index=False)\n",
    "        return merged_test_input\n",
    "    \n",
    "    train_labelled = X.merge(Ratings, on='psu_hh_idcode', how='inner')\n",
    "    train_labelled.shape\n",
    "\n",
    "    labelled_ids = set(Ratings['psu_hh_idcode'])\n",
    "    print(\"Count of labelled ID's:\", len(labelled_ids))\n",
    "\n",
    "    cols = ['psu_hh_idcode', 'subjectivePoverty_rating'] + [col for col in train_labelled.columns if col not in ['psu_hh_idcode', 'subjectivePoverty_rating']]\n",
    "    train_labelled = train_labelled[cols]\n",
    "    train_labelled = train_labelled.drop(columns=['hhid'])\n",
    "\n",
    "    if impute_ratings == False: \n",
    "        print(\"train data [labelled only]:\", train_labelled.shape)\n",
    "        train_labelled.to_csv(save_to, index=False)\n",
    "        return train_labelled\n",
    "        \n",
    "\n",
    "\n",
    "    # Filling in missing subjectiveRating labels with the assumption \"same household => same rating\" \n",
    "    train_all = X.merge(Ratings[['psu_hh_idcode', 'subjectivePoverty_rating']], on='psu_hh_idcode', how='outer')\n",
    "    cols = ['psu_hh_idcode', 'hhid', 'subjectivePoverty_rating'] + [col for col in train_all.columns if col not in ['psu_hh_idcode', 'hhid', 'subjectivePoverty_rating']]\n",
    "    merged_train_outer = train_all[cols] # data frame containing all rows\n",
    "\n",
    "    ratings_by_household = train_all[train_all['subjectivePoverty_rating'].notna()][['hhid', 'subjectivePoverty_rating']]\n",
    "    ratings_by_household = ratings_by_household.groupby('hhid').mean().reset_index().rename(columns={'subjectivePoverty_rating': 'avg_rating_hh'})\n",
    "    ratings_by_household.head()\n",
    "\n",
    "    train_unlabelled = train_all[train_all['subjectivePoverty_rating'].isna()]\n",
    "    n_unlabelled = len(train_unlabelled)\n",
    "    print(f\"Count of unlablled ID's in Train Set: {n_unlabelled}\")\n",
    "\n",
    "    train_imputed = train_unlabelled.merge(ratings_by_household, on='hhid', how='left')\n",
    "    train_imputed = train_imputed.drop(columns=['subjectivePoverty_rating']).rename(columns={'avg_rating_hh': 'subjectivePoverty_rating'})\n",
    "\n",
    "    n_imputed = len(train_imputed[train_imputed['subjectivePoverty_rating'].notna()])\n",
    "    print(f\"Count of succesfully imputed ID's in Train Set: {n_imputed}\")\n",
    "    print(f\"=> {round(n_imputed/n_unlabelled * 100,1)}% of unlabelled data imputed\")\n",
    "    train_imputed_labelled = pd.concat([train_labelled.assign(imputed=0), train_imputed.assign(imputed=1)], axis=0, ignore_index=True)\n",
    "\n",
    "    # reorder cols\n",
    "    cols = ['psu_hh_idcode', 'hhid', 'subjectivePoverty_rating', 'imputed'] + [col for col in merged_train_outer.columns if col not in ['psu_hh_idcode', 'hhid', 'subjectivePoverty_rating', 'imputed']]\n",
    "    train_imputed_labelled = train_imputed_labelled[cols]\n",
    "\n",
    "\n",
    "    # # drop rows with missing ratings now (15% of all rows)\n",
    "    train_imputed_labelled = train_imputed_labelled[train_imputed_labelled['subjectivePoverty_rating'].notna()]\n",
    "\n",
    "    n_labelled = len(train_imputed_labelled[train_imputed_labelled['imputed'] == 0])\n",
    "    n = len(train_imputed_labelled)\n",
    "    print(f\"=> originally labelled data: {round(n_labelled/len(train_imputed_labelled)*100, 1)}% of training data ({n_labelled} out of {n})\")\n",
    "    print(f\"=> data from mean imputation: {round(n_imputed/len(train_imputed_labelled)*100, 1)}% of training data ({n_imputed} out of {n})\")\n",
    "\n",
    "    train_imputed_labelled = train_imputed_labelled.drop(columns=['hhid', 'imputed'])\n",
    "\n",
    "    print(\"train data [labelled and imputed]:\", train_imputed_labelled.shape)\n",
    "\n",
    "    train_imputed_labelled.to_csv(save_to, index=False)\n",
    "    return train_imputed_labelled\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Merged Train Set (Unfilled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (22406, 41)\n",
      "Count of labelled ID's: 5334\n",
      "train data [labelled only]: (5334, 41)\n"
     ]
    }
   ],
   "source": [
    "train_labelled = generate_merged_set(house_train, edu_train, Ratings, impute_ratings=False, save_to=\"../data/model_training/TRAIN_MERGED_UNFILLED_encoded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (22406, 41)\n",
      "Count of labelled ID's: 5334\n",
      "Count of unlablled ID's in Train Set: 17072\n",
      "Count of succesfully imputed ID's in Train Set: 13620\n",
      "=> 79.8% of unlabelled data imputed\n",
      "=> originally labelled data: 28.1% of training data (5334 out of 18954)\n",
      "=> data from mean imputation: 71.9% of training data (13620 out of 18954)\n",
      "train data [labelled and imputed]: (18954, 41)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psu_hh_idcode</th>\n",
       "      <th>subjectivePoverty_rating</th>\n",
       "      <th>q02</th>\n",
       "      <th>q03_1</th>\n",
       "      <th>q03_2</th>\n",
       "      <th>q03_3</th>\n",
       "      <th>q03_4</th>\n",
       "      <th>q03_5</th>\n",
       "      <th>q03_6</th>\n",
       "      <th>q03_7</th>\n",
       "      <th>...</th>\n",
       "      <th>Q11_5</th>\n",
       "      <th>Q11_6</th>\n",
       "      <th>Q11_7</th>\n",
       "      <th>Q11_8</th>\n",
       "      <th>Q11_9</th>\n",
       "      <th>Q11_10</th>\n",
       "      <th>Q11_11</th>\n",
       "      <th>Q11_12</th>\n",
       "      <th>Q11_13</th>\n",
       "      <th>Q19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_2_1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_3_1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_5_1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_11_1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_12_1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  psu_hh_idcode  subjectivePoverty_rating  q02  q03_1  q03_2  q03_3  q03_4  \\\n",
       "0         1_2_1                       2.0    1    1.0    0.0    0.0    0.0   \n",
       "1         1_3_1                       4.0    1    1.0    0.0    0.0    0.0   \n",
       "2         1_5_1                       6.0    1    1.0    0.0    0.0    0.0   \n",
       "3        1_11_1                       6.0    1    1.0    0.0    0.0    0.0   \n",
       "4        1_12_1                       4.0    2    1.0    0.0    0.0    0.0   \n",
       "\n",
       "   q03_5  q03_6  q03_7  ...  Q11_5  Q11_6  Q11_7  Q11_8  Q11_9  Q11_10  \\\n",
       "0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "1    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "2    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "3    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "4    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "\n",
       "   Q11_11  Q11_12  Q11_13  Q19  \n",
       "0     0.0     0.0     1.0  2.0  \n",
       "1     0.0     0.0     1.0  2.0  \n",
       "2     0.0     0.0     0.0  2.0  \n",
       "3     0.0     0.0     1.0  2.0  \n",
       "4     0.0     0.0     1.0  2.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_imputed_labelled = generate_merged_set(house_train, edu_train, Ratings, impute_ratings=True, save_to=\"../data/model_training/TRAIN_MERGED_FILLED_encoded.csv\")\n",
    "train_imputed_labelled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Test Input File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial HouseholdInfo training set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psu_hh_idcode</th>\n",
       "      <th>hhid</th>\n",
       "      <th>q02</th>\n",
       "      <th>q03</th>\n",
       "      <th>q04</th>\n",
       "      <th>q05y</th>\n",
       "      <th>q05m</th>\n",
       "      <th>q06</th>\n",
       "      <th>q07</th>\n",
       "      <th>q08</th>\n",
       "      <th>...</th>\n",
       "      <th>q13</th>\n",
       "      <th>q14</th>\n",
       "      <th>q15</th>\n",
       "      <th>q16</th>\n",
       "      <th>q17</th>\n",
       "      <th>q18</th>\n",
       "      <th>q19</th>\n",
       "      <th>q20</th>\n",
       "      <th>q21</th>\n",
       "      <th>q22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_7_1</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19400717</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_8_1</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19480715</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_10_1</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19430612</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  psu_hh_idcode  hhid  q02  q03       q04  q05y  q05m  q06  q07  q08  ...  \\\n",
       "0         1_7_1   107    1    1  19400717    72     1    1  1.0  2.0  ...   \n",
       "1         1_8_1   108    1    1  19480715    64     1    2  2.0  NaN  ...   \n",
       "2        1_10_1   110    1    1  19430612    69     2    1  1.0  2.0  ...   \n",
       "\n",
       "   q13  q14   q15  q16  q17  q18  q19  q20   q21  q22  \n",
       "0  2.0  2.0  90.0  NaN    2  NaN  2.0  2.0  90.0  NaN  \n",
       "1  3.0  2.0  61.0  NaN    2  NaN  3.0  2.0  85.0  NaN  \n",
       "2  2.0  2.0  75.0  NaN    2  NaN  3.0  2.0  66.0  NaN  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HouseholdInfo after dropping columns with high correlations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psu_hh_idcode</th>\n",
       "      <th>hhid</th>\n",
       "      <th>q02</th>\n",
       "      <th>q03_1</th>\n",
       "      <th>q03_2</th>\n",
       "      <th>q03_3</th>\n",
       "      <th>q03_4</th>\n",
       "      <th>q03_5</th>\n",
       "      <th>q03_6</th>\n",
       "      <th>q03_7</th>\n",
       "      <th>q03_8</th>\n",
       "      <th>q03_9</th>\n",
       "      <th>q03_10</th>\n",
       "      <th>q03_11</th>\n",
       "      <th>q03_12</th>\n",
       "      <th>q03_13</th>\n",
       "      <th>q03_14</th>\n",
       "      <th>q05</th>\n",
       "      <th>q09</th>\n",
       "      <th>q23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_7_1</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_8_1</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_10_1</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  psu_hh_idcode  hhid  q02  q03_1  q03_2  q03_3  q03_4  q03_5  q03_6  q03_7  \\\n",
       "0         1_7_1   107    1    1.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1         1_8_1   108    1    1.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2        1_10_1   110    1    1.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   q03_8  q03_9  q03_10  q03_11  q03_12  q03_13  q03_14  q05  q09  q23  \n",
       "0    0.0    0.0     0.0     0.0     0.0     0.0     0.0   72    0    0  \n",
       "1    0.0    0.0     0.0     0.0     0.0     0.0     0.0   64    0    0  \n",
       "2    0.0    0.0     0.0     0.0     0.0     0.0     0.0   69    0    0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Education training set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psu_hh_idcode</th>\n",
       "      <th>Q01</th>\n",
       "      <th>Q02</th>\n",
       "      <th>Q03</th>\n",
       "      <th>Q04</th>\n",
       "      <th>Q05</th>\n",
       "      <th>Q06</th>\n",
       "      <th>Q07</th>\n",
       "      <th>Q08</th>\n",
       "      <th>Q09</th>\n",
       "      <th>...</th>\n",
       "      <th>Q57</th>\n",
       "      <th>Q58</th>\n",
       "      <th>Q59</th>\n",
       "      <th>Q60</th>\n",
       "      <th>Q61</th>\n",
       "      <th>Q62</th>\n",
       "      <th>Q63</th>\n",
       "      <th>Q64</th>\n",
       "      <th>Q65</th>\n",
       "      <th>Q66</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>648_6_4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>756_3_3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>164_8_3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  psu_hh_idcode  Q01  Q02  Q03  Q04  Q05  Q06  Q07  Q08  Q09  ...  Q57  Q58  \\\n",
       "0       648_6_4    1    1    1  6.0  1.0  3.0  3.0  1.0  1.0  ...  2.0  NaN   \n",
       "1       756_3_3    1    1    1  6.0  1.0  3.0  0.0  1.0  1.0  ...  2.0  NaN   \n",
       "2       164_8_3    1    1    1  6.0  3.0  3.0  3.0  1.0  1.0  ...  2.0  NaN   \n",
       "\n",
       "   Q59  Q60  Q61  Q62  Q63  Q64  Q65  Q66  \n",
       "0  2.0  NaN  2.0  NaN  NaN  2.0  NaN  2.0  \n",
       "1  2.0  NaN  2.0  NaN  NaN  2.0  NaN  4.0  \n",
       "2  2.0  NaN  2.0  NaN  NaN  2.0  NaN  6.0  \n",
       "\n",
       "[3 rows x 67 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Columns to remove due to high correlation with another variate ['Q02', 'Q04', 'Q05', 'Q14', 'Q17', 'Q18']\n",
      "Education after dropping columns with high correlations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psu_hh_idcode</th>\n",
       "      <th>Q01</th>\n",
       "      <th>Q03</th>\n",
       "      <th>Q06</th>\n",
       "      <th>Q07</th>\n",
       "      <th>Q08</th>\n",
       "      <th>Q11</th>\n",
       "      <th>Q19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>648_6_4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>756_3_3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>164_8_3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  psu_hh_idcode  Q01  Q03  Q06  Q07  Q08  Q11  Q19\n",
       "0       648_6_4    1    1  3.0  3.0  1.0  NaN  NaN\n",
       "1       756_3_3    1    1  3.0  0.0  1.0  NaN  NaN\n",
       "2       164_8_3    1    1  3.0  3.0  1.0  NaN  NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (1334, 41)\n",
      "TEST_INPUT.csv: (1334, 40) => 39 features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1334, 40)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_test = import_house(\"../data/raw/test_HouseholdInfo.csv\")\n",
    "house_test = clean_house(house_test)\n",
    "\n",
    "edu_test = import_education(\"../data/raw/test_Education.csv\")\n",
    "edu_test = clean_edu(edu_test)\n",
    "\n",
    "merged_test_input = generate_merged_set(house_test, edu_test, impute_ratings=False, save_to=\"../data/clean/TEST_INPUT_encoded.csv\")\n",
    "merged_test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1334, 40)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"../data/clean/TEST_INPUT_encoded.csv\")\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
