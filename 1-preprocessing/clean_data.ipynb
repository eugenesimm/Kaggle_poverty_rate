{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RAW_DATA_DIR = \"../data/raw/\"\n",
    "CLEAN_DATA_DIR = \"../data/clean/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Cleaning\n",
    "- column name formatting\n",
    "- generating primary key psu_hh_idcode\n",
    "- removing columns with high NA rates with threshold\n",
    "- removing columns with multi-colinearity\n",
    "- mapping binary responses to 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_education_train(path=os.path.join(RAW_DATA_DIR, \"train_Education.csv\")): \n",
    "    Education = pd.read_csv(path)\n",
    "    Education['psu_hh_idcode'] = Education['psu'].astype(str) + '_' + Education['hh'].astype(str) + '_' + Education['idcode'].astype(str)\n",
    "    Education.drop(columns=['psu', 'hh', 'idcode'], inplace=True)\n",
    "    Education = Education[['psu_hh_idcode'] + [col for col in Education.columns if col != 'psu_hh_idcode']]\n",
    "    Education.columns = [col.capitalize() if col.lower().startswith('q') else col for col in Education.columns]\n",
    "    print(\"Initial Education training set:\")\n",
    "    display(Education.head(3))\n",
    "    return Education\n",
    "\n",
    "def import_house_train(path=os.path.join(RAW_DATA_DIR, \"train_HouseholdInfo.csv\")):\n",
    "    HouseholdInfo = pd.read_csv(path)\n",
    "    HouseholdInfo['psu_hh_idcode'] = HouseholdInfo['psu'].astype(str) + '_' + HouseholdInfo['hh'].astype(str) + '_' + HouseholdInfo['idcode'].astype(str)\n",
    "    HouseholdInfo = HouseholdInfo[['psu_hh_idcode'] + [col for col in HouseholdInfo.columns if col != 'psu_hh_idcode']]\n",
    "    HouseholdInfo.drop(columns=['psu', 'idcode', 'hh'], inplace=True)\n",
    "    print(\"Initial HouseholdInfo training set:\")\n",
    "    display(HouseholdInfo.head(3))\n",
    "    return HouseholdInfo\n",
    "\n",
    "def remove_cols_high_na(df, threshold=0.3):\n",
    "    # NA rate\n",
    "    na_counts = df.isna().sum()\n",
    "    nrow = len(df)\n",
    "    na_rate = na_counts / nrow\n",
    "    na_rate = na_rate.sort_values(ascending=False)\n",
    "    cols_to_drop = na_rate[na_rate > threshold] # default threshold = 30%\n",
    "    print(f\"=> Removed {len(cols_to_drop)} Columns from Education due to NA rates above threshold={threshold*100}%\\n\")\n",
    "    # display(list(cols_to_drop.index))\n",
    "\n",
    "    df = df.drop(columns=cols_to_drop.index)\n",
    "    print(\"Education after dropping columns with high NA rate:\")\n",
    "    display(df.head(3))\n",
    "    return df\n",
    "\n",
    "def correlational_matrix_heatmap(data, fig_size=(6,6), cols_to_exclude=[]):\n",
    "    data_variates = data.drop(columns=cols_to_exclude)\n",
    "    cor_matrix = data_variates.corr()\n",
    "    \n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=fig_size)\n",
    "    ax = sns.heatmap(cor_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", cbar=False)\n",
    "\n",
    "    # Move x-axis labels to the top\n",
    "    ax.xaxis.tick_top()  # Moves x-axis labels to the top\n",
    "    ax.xaxis.set_label_position('top')  # Sets the label position to the top\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning HouseholdInfo Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_train = import_house_train(path=os.path.join(RAW_DATA_DIR, \"train_HouseholdInfo.csv\"))\n",
    "house_train = remove_cols_high_na(house_train, threshold=0.1)\n",
    "\n",
    "# Basic cleaning\n",
    "house_train.drop(columns=['q04'], inplace=True) # dropping q04 because date of birth is unnecessary when we have age\n",
    "house_train['q05'] = house_train['q05y'] # age is just in years, not years,months\n",
    "house_train.drop(columns=['q05y', 'q05m'], inplace=True)\n",
    "\n",
    "print(\"Correlation Matrix to check Multi-colinearity\")\n",
    "correlational_matrix_heatmap(house_train, fig_size=(6,6), cols_to_exclude=['psu_hh_idcode', 'hhid'])\n",
    "\n",
    "# AFTER CORRELATION ANALYSIS\n",
    "house_train.drop(columns=['q10'], inplace=True) # q10 has 0 variance, its not very useful as an explanatory variable. get rid of it\n",
    "\n",
    "# Map binary responses to 1 (yes) or 0 (no)\n",
    "house_train['q11'] = house_train['q11'].map({1: 'Yes', 2: 'No'}).map({'Yes': 1, 'No': 0})\n",
    "\n",
    "house_train['q17'] = house_train['q17'].map({1: 'Yes', 2: 'No'}).map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# q11 and q17 seems to be highly correlated so we decided to combine the two\n",
    "house_train['q23'] = house_train['q11'] + house_train['q17']\n",
    "house_train.drop(columns=['q11', 'q17'], inplace=True)\n",
    "\n",
    "# Sort columns order\n",
    "house_train = house_train[['psu_hh_idcode', 'hhid'] + [col for col in house_train.columns.sort_values() if col not in ['psu_hh_idcode', 'hhid']]]\n",
    "print(\"HouseholdInfo after dropping columns with high correlations\")\n",
    "display(house_train.head(3))\n",
    "\n",
    "correlational_matrix_heatmap(house_train, fig_size=(6,6), cols_to_exclude=['psu_hh_idcode', 'hhid'])\n",
    "\n",
    "# Output to CSV\n",
    "house_train.to_csv(os.path.join(CLEAN_DATA_DIR, \"train_HouseholdInfo_clean.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Education Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_train = import_education_train(path=os.path.join(RAW_DATA_DIR, \"train_Education.csv\"))\n",
    "edu_train = remove_cols_high_na(edu_train, threshold=0.3)\n",
    "print(\"Correlation Matrix to check Multi-colinearity\")\n",
    "correlational_matrix_heatmap(edu_train, fig_size=(8,8), cols_to_exclude='psu_hh_idcode')\n",
    "\n",
    "cols_to_drop_multicolinear = ['Q02', 'Q04', 'Q05', 'Q14', 'Q17', 'Q18']\n",
    "edu_train.drop(columns=cols_to_drop_multicolinear, inplace=True)\n",
    "print(\"=> Columns to remove due to high correlation with another variate\", cols_to_drop_multicolinear)\n",
    "\n",
    "print(\"Education after dropping columns with high correlations\")\n",
    "display(edu_train.head(3))\n",
    "\n",
    "correlational_matrix_heatmap(edu_train, fig_size=(6,6), cols_to_exclude='psu_hh_idcode')\n",
    "\n",
    "# Output to CSV\n",
    "edu_train.to_csv(os.path.join(CLEAN_DATA_DIR, \"train_Education_clean.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SubjectivePoverty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psu_hh_idcode</th>\n",
       "      <th>subjectivePoverty_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30_8_1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194_1_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>224_6_1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  psu_hh_idcode  subjectivePoverty_rating\n",
       "0        30_8_1                         4\n",
       "1       194_1_2                         1\n",
       "2       224_6_1                         3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SubjectivePoverty = pd.read_csv(os.path.join(RAW_DATA_DIR, \"train_SubjectivePoverty.csv\"))\n",
    "subjective_poverty_columns = [f'subjective_poverty_{i}' for i in range(1, 11)]\n",
    "SubjectivePoverty['subjectivePoverty_rating'] = SubjectivePoverty[subjective_poverty_columns].idxmax(axis=1).str.extract('(\\d+)').astype(int)\n",
    "Ratings = SubjectivePoverty[['psu_hh_idcode', 'subjectivePoverty_rating']]\n",
    "\n",
    "# Three of the subjects in SubjectivePoverty train set do not show up in either Education or Household train sets. We get rid of these from subjectivePoverty\n",
    "# Get the IDs from household and education DataFrames\n",
    "household_ids = set(house_train['psu_hh_idcode'])\n",
    "education_ids = set(edu_train['psu_hh_idcode'])\n",
    "valid_ids = household_ids.union(education_ids)\n",
    "# Filter ratings_df to keep only rows with IDs present in valid_ids\n",
    "Ratings = Ratings[Ratings['psu_hh_idcode'].isin(valid_ids)]\n",
    "\n",
    "display(Ratings.head(3))\n",
    "\n",
    "Ratings.to_csv(os.path.join(CLEAN_DATA_DIR, \"train_SubjectivePoverty_clean.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Merged Train Set (Unfilled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (22406, 14)\n",
      "Count of labelled ID's: 5334\n"
     ]
    }
   ],
   "source": [
    "X = house_train.merge(edu_train, on='psu_hh_idcode', how='inner')\n",
    "print(f\"X.shape: {X.shape}\")\n",
    "train_labelled = X.merge(Ratings, on='psu_hh_idcode', how='inner')\n",
    "train_labelled.shape\n",
    "\n",
    "# psu_hh_idcodes with ground truth labels:\n",
    "labelled_ids = set(Ratings['psu_hh_idcode'])\n",
    "print(\"Count of labelled ID's:\", len(labelled_ids))\n",
    "\n",
    "cols = ['psu_hh_idcode', 'subjectivePoverty_rating'] + [col for col in train_labelled.columns if col not in ['psu_hh_idcode', 'subjectivePoverty_rating']]\n",
    "train_labelled = train_labelled[cols]\n",
    "train_labelled.to_csv(os.path.join(CLEAN_DATA_DIR, \"TRAIN_MERGED_UNFILLED.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of unlablled ID's in Train Set: 17072\n",
      "Count of succesfully imputed ID's in Train Set: 13620\n",
      "=> 79.8% of unlabelled data imputed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psu_hh_idcode</th>\n",
       "      <th>hhid</th>\n",
       "      <th>subjectivePoverty_rating</th>\n",
       "      <th>imputed</th>\n",
       "      <th>q02</th>\n",
       "      <th>q03</th>\n",
       "      <th>q05</th>\n",
       "      <th>q09</th>\n",
       "      <th>q23</th>\n",
       "      <th>Q01</th>\n",
       "      <th>Q03</th>\n",
       "      <th>Q06</th>\n",
       "      <th>Q07</th>\n",
       "      <th>Q08</th>\n",
       "      <th>Q11</th>\n",
       "      <th>Q19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_2_1</td>\n",
       "      <td>102</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_3_1</td>\n",
       "      <td>103</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_5_1</td>\n",
       "      <td>105</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_11_1</td>\n",
       "      <td>111</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_12_1</td>\n",
       "      <td>112</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  psu_hh_idcode  hhid  subjectivePoverty_rating  imputed  q02  q03  q05  q09  \\\n",
       "0         1_2_1   102                       2.0        0    1    1   52    0   \n",
       "1         1_3_1   103                       4.0        0    1    1   58    0   \n",
       "2         1_5_1   105                       6.0        0    1    1   54    0   \n",
       "3        1_11_1   111                       6.0        0    1    1   44    0   \n",
       "4        1_12_1   112                       4.0        0    2    1   54    0   \n",
       "\n",
       "   q23  Q01  Q03  Q06  Q07  Q08   Q11  Q19  \n",
       "0    0    1    1  2.0  1.0  2.0  13.0  2.0  \n",
       "1    0    1    1  9.0  1.0  2.0  13.0  2.0  \n",
       "2    0    1    1  1.0  0.0  2.0   2.0  2.0  \n",
       "3    0    1    1  3.0  1.0  2.0  13.0  2.0  \n",
       "4    0    1    1  3.0  1.0  2.0  13.0  2.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> originally labelled data: 28.1% of training data (5334 out of 18954)\n",
      "=> data from mean imputation: 71.9% of training data (13620 out of 18954)\n",
      "train data [labelled and imputed]: (18954, 14)\n"
     ]
    }
   ],
   "source": [
    "X = house_train.merge(edu_train, on='psu_hh_idcode', how='inner')\n",
    "\n",
    "# Filling in missing subjectiveRating labels with the assumption \"same household => same rating\" \n",
    "train_all = X.merge(Ratings[['psu_hh_idcode', 'subjectivePoverty_rating']], on='psu_hh_idcode', how='outer')\n",
    "cols = ['psu_hh_idcode', 'hhid', 'subjectivePoverty_rating'] + [col for col in train_all.columns if col not in ['psu_hh_idcode', 'hhid', 'subjectivePoverty_rating']]\n",
    "merged_train_outer = train_all[cols] # data frame containing all rows\n",
    "\n",
    "ratings_by_household = train_all[train_all['subjectivePoverty_rating'].notna()][['hhid', 'subjectivePoverty_rating']]\n",
    "ratings_by_household = ratings_by_household.groupby('hhid').mean().reset_index().rename(columns={'subjectivePoverty_rating': 'avg_rating_hh'})\n",
    "ratings_by_household.head()\n",
    "\n",
    "train_unlabelled = train_all[train_all['subjectivePoverty_rating'].isna()]\n",
    "n_unlabelled = len(train_unlabelled)\n",
    "print(f\"Count of unlablled ID's in Train Set: {n_unlabelled}\")\n",
    "\n",
    "train_imputed = train_unlabelled.merge(ratings_by_household, on='hhid', how='left')\n",
    "train_imputed = train_imputed.drop(columns=['subjectivePoverty_rating']).rename(columns={'avg_rating_hh': 'subjectivePoverty_rating'})\n",
    "\n",
    "n_imputed = len(train_imputed[train_imputed['subjectivePoverty_rating'].notna()])\n",
    "print(f\"Count of succesfully imputed ID's in Train Set: {n_imputed}\")\n",
    "print(f\"=> {round(n_imputed/n_unlabelled * 100,1)}% of unlabelled data imputed\")\n",
    "train_imputed_labelled = pd.concat([train_labelled.assign(imputed=0), train_imputed.assign(imputed=1)], axis=0, ignore_index=True)\n",
    "\n",
    "# reorder cols\n",
    "cols = ['psu_hh_idcode', 'hhid', 'subjectivePoverty_rating', 'imputed'] + [col for col in merged_train_outer.columns if col not in ['psu_hh_idcode', 'hhid', 'subjectivePoverty_rating', 'imputed']]\n",
    "train_imputed_labelled = train_imputed_labelled[cols]\n",
    "\n",
    "\n",
    "# # drop rows with missing ratings now (15% of all rows)\n",
    "train_imputed_labelled = train_imputed_labelled[train_imputed_labelled['subjectivePoverty_rating'].notna()]\n",
    "\n",
    "display(train_imputed_labelled.head())\n",
    "n_labelled = len(train_imputed_labelled[train_imputed_labelled['imputed'] == 0])\n",
    "n = len(train_imputed_labelled)\n",
    "print(f\"=> originally labelled data: {round(n_labelled/len(train_imputed_labelled)*100, 1)}% of training data ({n_labelled} out of {n})\")\n",
    "print(f\"=> data from mean imputation: {round(n_imputed/len(train_imputed_labelled)*100, 1)}% of training data ({n_imputed} out of {n})\")\n",
    "\n",
    "train_imputed_labelled = train_imputed_labelled.drop(columns=['hhid', 'imputed'])\n",
    "\n",
    "\n",
    "print(\"train data [labelled and imputed]:\", train_imputed_labelled.shape)\n",
    "# # OUTPUT TO CSV\n",
    "train_imputed_labelled.to_csv(os.path.join(CLEAN_DATA_DIR, \"TRAIN_MERGED_FILLED.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing Values Training Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Education_clean = pd.read_csv(os.path.join(CLEAN_DATA_DIR, \"train_Education_clean.csv\"))\n",
    "# HouseholdInfo_clean = pd.read_csv(os.path.join(CLEAN_DATA_DIR, \"train_HouseholdInfo_clean_csv\"))\n",
    "# Ratings_clean = pd.read_csv(os.path.join(CLEAN_DATA_DIR, \"train_SubjectivePoverty_clean.csv\"))\n",
    "train_labelled = pd.read_csv(os.path.join(CLEAN_DATA_DIR, \"TRAIN_MERGED_UNFILLED.csv\"))\n",
    "# train_imputed_labelled.isna().mean()\n",
    "train_labelled['Q06'] = train_labelled['Q06'].fillna(-1)\n",
    "train_labelled['Q07'] = train_labelled['Q07'].fillna(-1)\n",
    "train_labelled['Q08'] = train_labelled['Q08'].fillna(-1)\n",
    "train_labelled['Q11'] = train_labelled['Q11'].fillna(-1)\n",
    "train_labelled['Q19'] = train_labelled['Q19'].fillna(-1)\n",
    "\n",
    "train_labelled.isna().mean()\n",
    "\n",
    "train_labelled.to_csv(os.path.join(CLEAN_DATA_DIR, \"TRAIN_MERGED_UNFILLED.csv\"), index=False)\n",
    "\n",
    "\n",
    "train_imputed_labelled = pd.read_csv(os.path.join(CLEAN_DATA_DIR, \"TRAIN_MERGED_FILLED.csv\"))\n",
    "train_imputed_labelled['Q06'] = train_imputed_labelled['Q06'].fillna(-1)\n",
    "train_imputed_labelled['Q07'] = train_imputed_labelled['Q07'].fillna(-1)\n",
    "train_imputed_labelled['Q08'] = train_imputed_labelled['Q08'].fillna(-1)\n",
    "train_imputed_labelled['Q11'] = train_imputed_labelled['Q11'].fillna(-1)\n",
    "train_imputed_labelled['Q19'] = train_imputed_labelled['Q19'].fillna(-1)\n",
    "\n",
    "train_imputed_labelled.to_csv(os.path.join(CLEAN_DATA_DIR, \"TRAIN_MERGED_FILLED.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>psu_hh_idcode</th>\n",
       "      <th>hhid</th>\n",
       "      <th>subjectivePoverty_rating</th>\n",
       "      <th>q02</th>\n",
       "      <th>q03</th>\n",
       "      <th>q05</th>\n",
       "      <th>q09</th>\n",
       "      <th>q23</th>\n",
       "      <th>Q01</th>\n",
       "      <th>Q03</th>\n",
       "      <th>Q06</th>\n",
       "      <th>Q07</th>\n",
       "      <th>Q08</th>\n",
       "      <th>Q11</th>\n",
       "      <th>Q19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30_8_1</td>\n",
       "      <td>3008</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>194_1_2</td>\n",
       "      <td>19401</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>224_6_1</td>\n",
       "      <td>22406</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>323_10_1</td>\n",
       "      <td>32310</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>428_10_1</td>\n",
       "      <td>42810</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 psu_hh_idcode   hhid  subjectivePoverty_rating  q02  q03  q05  \\\n",
       "0           0        30_8_1   3008                         4    1    1   44   \n",
       "1           1       194_1_2  19401                         1    2    2   48   \n",
       "2           2       224_6_1  22406                         3    1    1   61   \n",
       "3           3      323_10_1  32310                         5    1    1   66   \n",
       "4           4      428_10_1  42810                         4    2    1   72   \n",
       "\n",
       "   q09  q23  Q01  Q03  Q06  Q07  Q08   Q11  Q19  \n",
       "0    0    0    1    1  2.0  1.0  2.0  13.0  2.0  \n",
       "1    0    0    1    1  2.0  0.0  2.0  13.0  2.0  \n",
       "2    0    0    1    1  2.0  0.0  2.0  13.0  2.0  \n",
       "3    0    0    1    1  2.0  0.0  2.0  13.0  2.0  \n",
       "4    0    0    1    1  1.0  0.0  2.0  14.0  2.0  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labelled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Test Input File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_HouseholdInfo.csv: (1334, 6) => 5 features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psu_hh_idcode</th>\n",
       "      <th>q02</th>\n",
       "      <th>q03</th>\n",
       "      <th>q05</th>\n",
       "      <th>q09</th>\n",
       "      <th>q23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_7_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_8_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_10_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  psu_hh_idcode  q02  q03  q05  q09  q23\n",
       "0         1_7_1    1    1   72    0    4\n",
       "1         1_8_1    1    1   64    0    4\n",
       "2        1_10_1    1    1   69    0    4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test_Education.csv: (1334, 8) => 7 features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psu_hh_idcode</th>\n",
       "      <th>Q01</th>\n",
       "      <th>Q03</th>\n",
       "      <th>Q06</th>\n",
       "      <th>Q07</th>\n",
       "      <th>Q08</th>\n",
       "      <th>Q11</th>\n",
       "      <th>Q19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>648_6_4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>756_3_3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>164_8_3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  psu_hh_idcode  Q01  Q03  Q06  Q07  Q08  Q11  Q19\n",
       "0       648_6_4    1    1  3.0  3.0  1.0  NaN  NaN\n",
       "1       756_3_3    1    1  3.0  0.0  1.0  NaN  NaN\n",
       "2       164_8_3    1    1  3.0  3.0  1.0  NaN  NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns with missing data:\n",
      "\n",
      "Q06: [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 9.0, nan, 10.0, 11.0]\n",
      "Q07: [0.0, 1.0, 2.0, 4.0, nan, 3.0]\n",
      "Q08: [2.0, nan, 1.0]\n",
      "Q11: [1.0, 2.0, 3.0, 4.0, 8.0, 13.0, nan, 10.0, 12.0, 14.0]\n",
      "Q19: [2.0, nan, 1.0]\n",
      "TEST_INPUT.csv: (1334, 13) => 12 features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psu_hh_idcode</th>\n",
       "      <th>q02</th>\n",
       "      <th>q03</th>\n",
       "      <th>q05</th>\n",
       "      <th>q09</th>\n",
       "      <th>q23</th>\n",
       "      <th>Q01</th>\n",
       "      <th>Q03</th>\n",
       "      <th>Q06</th>\n",
       "      <th>Q07</th>\n",
       "      <th>Q08</th>\n",
       "      <th>Q11</th>\n",
       "      <th>Q19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_7_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_8_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_10_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2_3_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3_1_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  psu_hh_idcode  q02  q03  q05  q09  q23  Q01  Q03  Q06  Q07  Q08   Q11  Q19\n",
       "0         1_7_1    1    1   72    0    4    1    1  1.0  1.0  2.0  13.0  2.0\n",
       "1         1_8_1    1    1   64    0    4    1    1  2.0  1.0  2.0  13.0  2.0\n",
       "2        1_10_1    1    1   69    0    4    1    1  9.0  0.0  2.0  13.0  2.0\n",
       "3         2_3_1    1    1   53    0    4    1    1  3.0  0.0  2.0   2.0  2.0\n",
       "4         3_1_1    1    1   48    0    4    1    1  2.0  0.0  2.0   2.0  2.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols_to_keep = ['psu_hh_idcode', 'hhid', 'subjectivePoverty_rating', 'q02', 'q03', 'q05', 'q09', 'q23', 'Q01', 'Q03', 'Q06', 'Q07', 'Q08', 'Q11', 'Q19']\n",
    "\n",
    "house_test = pd.read_csv(os.path.join(RAW_DATA_DIR, \"test_HouseholdInfo.csv\"))\n",
    "house_test['psu_hh_idcode'] = house_test['psu'].astype(str) + '_' + house_test['hh'].astype(str) + '_' + house_test['idcode'].astype(str)\n",
    "house_test.drop(columns=['psu', 'hh', 'idcode', 'hhid'], inplace=True)\n",
    "house_test['q05'] = house_test['q05y']\n",
    "house_test['q23'] = house_test['q11'] + house_test['q17']\n",
    "house_test = house_test.drop(columns=[col for col in house_test.columns if col not in cols_to_keep])\n",
    "house_test = house_test[['psu_hh_idcode', 'q02', 'q03', 'q05', 'q09', 'q23']]\n",
    "print(\"test_HouseholdInfo.csv:\", house_test.shape, f\"=> {house_test.shape[1]-1} features\")\n",
    "display(house_test.head(3))\n",
    "\n",
    "edu_test = pd.read_csv(os.path.join(RAW_DATA_DIR, \"test_Education.csv\"))\n",
    "edu_test['psu_hh_idcode'] = edu_test['psu'].astype(str) + '_' + edu_test['hh'].astype(str) + '_' + edu_test['idcode'].astype(str)\n",
    "edu_test.columns = [col.capitalize() if col.lower().startswith('q') else col for col in edu_test.columns]\n",
    "edu_test = edu_test.drop(columns=['psu', 'hh', 'idcode'])\n",
    "edu_test.drop(columns=[col for col in edu_test.columns if col not in cols_to_keep], inplace=True)\n",
    "edu_test = edu_test[['psu_hh_idcode', 'Q01', 'Q03', 'Q06', 'Q07', 'Q08', 'Q11', 'Q19']]\n",
    "print()\n",
    "print(\"test_Education.csv:\", edu_test.shape, f\"=> {edu_test.shape[1]-1} features\")\n",
    "display(edu_test.head(3))\n",
    "\n",
    "merged_test_input = house_test.merge(edu_test, on='psu_hh_idcode', how='inner')\n",
    "print()\n",
    "print(\"Columns with missing data:\\n\")\n",
    "for col in ['Q06', 'Q07', 'Q08', 'Q11', 'Q19']:\n",
    "    print(f\"{col}:\", sorted(list(merged_test_input[col].unique())))\n",
    "\n",
    "# OKAY how do we fill in missing vals in each col\n",
    "# Q06\n",
    "# Q07\n",
    "# Q08\n",
    "# Q11\n",
    "# Q19\n",
    "# => fill with -1 for now\n",
    "merged_test_input['Q06'] = merged_test_input['Q06'].fillna(-1)\n",
    "merged_test_input['Q07'] = merged_test_input['Q07'].fillna(-1)\n",
    "merged_test_input['Q08'] = merged_test_input['Q08'].fillna(-1)\n",
    "merged_test_input['Q11'] = merged_test_input['Q11'].fillna(-1)\n",
    "merged_test_input['Q19'] = merged_test_input['Q19'].fillna(-1)\n",
    "\n",
    "print(\"TEST_INPUT.csv:\", merged_test_input.shape, f\"=> {merged_test_input.shape[1]-1} features\")\n",
    "display(merged_test_input.head())\n",
    "display(merged_test_input.isna().mean())\n",
    "# Output to CSV\n",
    "merged_test_input.to_csv(os.path.join(CLEAN_DATA_DIR, \"TEST_INPUT.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
