{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import log_loss, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "CLEAN_DATA_DIR = \"../data/clean/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(data):\n",
    "  col = [col for col in data.columns if -1 in data[col].values]\n",
    "  # One-hot encode categorical columns\n",
    "  encoder = OneHotEncoder(sparse_output=False, drop=None)\n",
    "  encoded = encoder.fit_transform(data[col])\n",
    "\n",
    "  # Convert to DataFrame and combine with numerical features\n",
    "  encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(col), index=data.index)\n",
    "  numerical_df = data.drop(columns=col)\n",
    "\n",
    "  # Combine numerical and encoded categorical data\n",
    "  processed_df = pd.concat([numerical_df, encoded_df], axis=1)\n",
    "  return processed_df\n",
    "\n",
    "\n",
    "def encode_filler(data):\n",
    "  na_col = ['Q06_11.0', 'Q11_5.0', 'Q06_10.0', 'Q11_9.0', 'Q06_9.0', 'Q07_-1.0', 'Q06_2.0', 'Q01', 'Q11_14.0', 'Q06_5.0',\n",
    "              'Q11_2.0', 'Q06_4.0', 'Q08_-1.0', 'Q07_4.0', 'Q08_2.0', 'Q07_0.0', 'q02', 'Q06_8.0', 'Q07_2.0', 'Q11_3.0', 'Q03',\n",
    "              'Q11_4.0', 'q23', 'Q11_7.0', 'Q11_13.0', 'Q06_1.0', 'Q19_2.0', 'Q06_-1.0', 'Q11_-1.0', 'Q11_10.0', 'q05', 'Q07_1.0',\n",
    "              'Q11_12.0', 'Q19_-1.0', 'Q06_7.0', 'Q11_1.0', 'Q19_1.0', 'Q11_8.0', 'Q08_1.0', 'Q06_0.0', 'q03', 'Q06_3.0', 'q09',\n",
    "              'Q07_3.0', 'Q11_11.0', 'Q06_6.0']\n",
    "\n",
    "  for col in na_col:\n",
    "      if col not in data.columns:\n",
    "          data[col] = 0  # Assign 0\n",
    "  \n",
    "  filled_data = data[na_col]\n",
    "  return filled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ratings_SVM(train_data):\n",
    "\n",
    "    train_x = train_data.drop(columns=['psu_hh_idcode', 'subjectivePoverty_rating'])\n",
    "\n",
    "    # Combine numerical and encoded categorical data\n",
    "    processed_train = encoder(train_x)\n",
    "    processed_train = encode_filler(processed_train)\n",
    "\n",
    "    y = train_data['subjectivePoverty_rating']\n",
    "    X = processed_train\n",
    "\n",
    "  \n",
    "    # Scale the features\n",
    "    # scaler = StandardScaler()\n",
    "    # X_train_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "   # GridSearch CV\n",
    "    param_grid = {\n",
    "        'C': [0.5, 1, 10, 100],\n",
    "        'gamma': ['scale', 0.1, 0.01, 0.001],\n",
    "        'kernel': ['rbf']\n",
    "    }\n",
    "\n",
    "    optimal_params = GridSearchCV(SVC(probability=True, random_state=42), param_grid, n_jobs=-1, cv=5, scoring='neg_log_loss')\n",
    "    \n",
    "    # Fit the model\n",
    "    optimal_params.fit(X, y)\n",
    "    return optimal_params.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_DATA_DIR = \"../data/model_result/\"\n",
    "train_data = pd.read_csv(os.path.join(CLEAN_DATA_DIR, \"TRAIN_MERGED_UNFILLED.csv\"))\n",
    "\n",
    "train_A, train_B = train_test_split(train_data, test_size=0.25, stratify=train_data['subjectivePoverty_rating'], random_state=42)\n",
    "\n",
    "model = predict_ratings_SVM(train_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_B_X = train_B.drop(columns=['subjectivePoverty_rating'])\n",
    "# display(train_B_X)\n",
    "\n",
    "def predictratings_SVM(model, train_B_X):\n",
    "    test_ids = train_B_X['psu_hh_idcode']\n",
    "    train_B_X = encoder(train_B_X)\n",
    "    train_B_X = encode_filler(train_B_X)\n",
    "    preds_proba = model.predict_proba(train_B_X)\n",
    "    print(log_loss(train_B['subjectivePoverty_rating'], preds_proba))\n",
    "    output_df = pd.DataFrame(preds_proba, columns=[f'subjective_poverty{i+1}' for i in range(preds_proba.shape[1])])\n",
    "    output_df.insert(0, 'psu_hh_idcode', test_ids.values)  # Insert the ID column at the start\n",
    "    return output_df\n",
    "\n",
    "pred = predictratings_SVM(model, train_B_X)\n",
    "display(pred)\n",
    "\n",
    "#1.9505287965222604 - scale X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9847676398932983\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psu_hh_idcode</th>\n",
       "      <th>subjective_poverty1</th>\n",
       "      <th>subjective_poverty2</th>\n",
       "      <th>subjective_poverty3</th>\n",
       "      <th>subjective_poverty4</th>\n",
       "      <th>subjective_poverty5</th>\n",
       "      <th>subjective_poverty6</th>\n",
       "      <th>subjective_poverty7</th>\n",
       "      <th>subjective_poverty8</th>\n",
       "      <th>subjective_poverty9</th>\n",
       "      <th>subjective_poverty10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125_11_1</td>\n",
       "      <td>0.037714</td>\n",
       "      <td>0.088038</td>\n",
       "      <td>0.162156</td>\n",
       "      <td>0.206846</td>\n",
       "      <td>0.206600</td>\n",
       "      <td>0.153097</td>\n",
       "      <td>0.087770</td>\n",
       "      <td>0.046170</td>\n",
       "      <td>0.009439</td>\n",
       "      <td>0.002170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129_9_1</td>\n",
       "      <td>0.044272</td>\n",
       "      <td>0.099092</td>\n",
       "      <td>0.177918</td>\n",
       "      <td>0.225486</td>\n",
       "      <td>0.119236</td>\n",
       "      <td>0.167930</td>\n",
       "      <td>0.096035</td>\n",
       "      <td>0.053468</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.004363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>800_8_1</td>\n",
       "      <td>0.037609</td>\n",
       "      <td>0.086254</td>\n",
       "      <td>0.162107</td>\n",
       "      <td>0.206880</td>\n",
       "      <td>0.207113</td>\n",
       "      <td>0.153115</td>\n",
       "      <td>0.089702</td>\n",
       "      <td>0.046112</td>\n",
       "      <td>0.009003</td>\n",
       "      <td>0.002106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>472_1_1</td>\n",
       "      <td>0.037549</td>\n",
       "      <td>0.084711</td>\n",
       "      <td>0.162122</td>\n",
       "      <td>0.206384</td>\n",
       "      <td>0.205959</td>\n",
       "      <td>0.152950</td>\n",
       "      <td>0.092459</td>\n",
       "      <td>0.046198</td>\n",
       "      <td>0.009504</td>\n",
       "      <td>0.002163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>309_11_1</td>\n",
       "      <td>0.037491</td>\n",
       "      <td>0.084642</td>\n",
       "      <td>0.162476</td>\n",
       "      <td>0.206771</td>\n",
       "      <td>0.207688</td>\n",
       "      <td>0.154264</td>\n",
       "      <td>0.091087</td>\n",
       "      <td>0.046064</td>\n",
       "      <td>0.007451</td>\n",
       "      <td>0.002066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>588_5_1</td>\n",
       "      <td>0.037643</td>\n",
       "      <td>0.087379</td>\n",
       "      <td>0.162128</td>\n",
       "      <td>0.206865</td>\n",
       "      <td>0.206794</td>\n",
       "      <td>0.153098</td>\n",
       "      <td>0.088508</td>\n",
       "      <td>0.046156</td>\n",
       "      <td>0.009258</td>\n",
       "      <td>0.002172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>566_4_1</td>\n",
       "      <td>0.041635</td>\n",
       "      <td>0.093976</td>\n",
       "      <td>0.171549</td>\n",
       "      <td>0.217925</td>\n",
       "      <td>0.150267</td>\n",
       "      <td>0.161936</td>\n",
       "      <td>0.093466</td>\n",
       "      <td>0.050683</td>\n",
       "      <td>0.011375</td>\n",
       "      <td>0.007188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>220_7_1</td>\n",
       "      <td>0.037614</td>\n",
       "      <td>0.083467</td>\n",
       "      <td>0.162170</td>\n",
       "      <td>0.206784</td>\n",
       "      <td>0.207284</td>\n",
       "      <td>0.153168</td>\n",
       "      <td>0.092627</td>\n",
       "      <td>0.046017</td>\n",
       "      <td>0.008822</td>\n",
       "      <td>0.002047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>144_5_2</td>\n",
       "      <td>0.038440</td>\n",
       "      <td>0.085921</td>\n",
       "      <td>0.162641</td>\n",
       "      <td>0.205601</td>\n",
       "      <td>0.205517</td>\n",
       "      <td>0.153733</td>\n",
       "      <td>0.090047</td>\n",
       "      <td>0.045666</td>\n",
       "      <td>0.008296</td>\n",
       "      <td>0.004137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>18_7_1</td>\n",
       "      <td>0.037576</td>\n",
       "      <td>0.083108</td>\n",
       "      <td>0.163179</td>\n",
       "      <td>0.207601</td>\n",
       "      <td>0.208446</td>\n",
       "      <td>0.152440</td>\n",
       "      <td>0.094225</td>\n",
       "      <td>0.045531</td>\n",
       "      <td>0.005826</td>\n",
       "      <td>0.002069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1334 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     psu_hh_idcode  subjective_poverty1  subjective_poverty2  \\\n",
       "0         125_11_1             0.037714             0.088038   \n",
       "1          129_9_1             0.044272             0.099092   \n",
       "2          800_8_1             0.037609             0.086254   \n",
       "3          472_1_1             0.037549             0.084711   \n",
       "4         309_11_1             0.037491             0.084642   \n",
       "...            ...                  ...                  ...   \n",
       "1329       588_5_1             0.037643             0.087379   \n",
       "1330       566_4_1             0.041635             0.093976   \n",
       "1331       220_7_1             0.037614             0.083467   \n",
       "1332       144_5_2             0.038440             0.085921   \n",
       "1333        18_7_1             0.037576             0.083108   \n",
       "\n",
       "      subjective_poverty3  subjective_poverty4  subjective_poverty5  \\\n",
       "0                0.162156             0.206846             0.206600   \n",
       "1                0.177918             0.225486             0.119236   \n",
       "2                0.162107             0.206880             0.207113   \n",
       "3                0.162122             0.206384             0.205959   \n",
       "4                0.162476             0.206771             0.207688   \n",
       "...                   ...                  ...                  ...   \n",
       "1329             0.162128             0.206865             0.206794   \n",
       "1330             0.171549             0.217925             0.150267   \n",
       "1331             0.162170             0.206784             0.207284   \n",
       "1332             0.162641             0.205601             0.205517   \n",
       "1333             0.163179             0.207601             0.208446   \n",
       "\n",
       "      subjective_poverty6  subjective_poverty7  subjective_poverty8  \\\n",
       "0                0.153097             0.087770             0.046170   \n",
       "1                0.167930             0.096035             0.053468   \n",
       "2                0.153115             0.089702             0.046112   \n",
       "3                0.152950             0.092459             0.046198   \n",
       "4                0.154264             0.091087             0.046064   \n",
       "...                   ...                  ...                  ...   \n",
       "1329             0.153098             0.088508             0.046156   \n",
       "1330             0.161936             0.093466             0.050683   \n",
       "1331             0.153168             0.092627             0.046017   \n",
       "1332             0.153733             0.090047             0.045666   \n",
       "1333             0.152440             0.094225             0.045531   \n",
       "\n",
       "      subjective_poverty9  subjective_poverty10  \n",
       "0                0.009439              0.002170  \n",
       "1                0.012200              0.004363  \n",
       "2                0.009003              0.002106  \n",
       "3                0.009504              0.002163  \n",
       "4                0.007451              0.002066  \n",
       "...                   ...                   ...  \n",
       "1329             0.009258              0.002172  \n",
       "1330             0.011375              0.007188  \n",
       "1331             0.008822              0.002047  \n",
       "1332             0.008296              0.004137  \n",
       "1333             0.005826              0.002069  \n",
       "\n",
       "[1334 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_TRAINING_DATA_DIR = \"../data/model_training/\"\n",
    "train_data = pd.read_csv(os.path.join(MODEL_TRAINING_DATA_DIR, \"TRAIN_MERGED_UNFILLED_encoded.csv\"))\n",
    "train_A, train_B = train_test_split(train_data, test_size=0.25, stratify=train_data['subjectivePoverty_rating'], random_state=42)\n",
    "\n",
    "model = predict_ratings_SVM(train_A)\n",
    "train_B_X = train_B.drop(columns=['subjectivePoverty_rating'])\n",
    "pred = predictratings_SVM(model, train_B_X)\n",
    "display(pred)\n",
    "\n",
    "#1.9847676398932983 - scale o"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
