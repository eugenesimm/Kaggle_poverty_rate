{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import log_loss, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "MODEL_TRAINING_DATA_DIR = \"../data/model_training/\"\n",
    "RESULT_DATA_DIR = \"../data/model_result/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ratings_SVM(train_data):\n",
    "\n",
    "    train_x = train_data.drop(columns=['psu_hh_idcode', 'subjectivePoverty_rating'])\n",
    "    y = train_data['subjectivePoverty_rating']\n",
    "\n",
    "    # Scale ordinal and numerical data\n",
    "    ordinal_col = ['q23', 'Q06']\n",
    "    numerical_col = ['q05', 'q09', 'Q07']\n",
    "    scalable_col = ordinal_col + numerical_col\n",
    "\n",
    "    scalable_x = train_x[scalable_col]\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    scaled_x = scaler.fit_transform(scalable_x)\n",
    "    scaled_x = pd.DataFrame(scaled_x, columns=scalable_x.columns, index=scalable_x.index)\n",
    "\n",
    "\n",
    "    # One-hot-encoding\n",
    "    ohc_col = ['q02', 'q03_1', 'q03_2', 'q03_3', 'q03_4', 'q03_5', 'q03_6', 'q03_7', 'q03_8', 'q03_9', 'q03_10',\n",
    "    'q03_11', 'q03_12', 'q03_13', 'q03_14', 'Q03', 'Q08', 'Q11_1', 'Q11_2', 'Q11_3', 'Q11_4',\n",
    "    'Q11_5', 'Q11_6', 'Q11_7', 'Q11_8', 'Q11_9', 'Q11_10', 'Q11_11', 'Q11_12', 'Q11_13', 'Q19',\n",
    "    'Q01_0', 'Q01_1', 'Q01_2']\n",
    "    ohc_x = train_x[ohc_col]\n",
    "    # ohc_x = encoder(ohc_x)\n",
    "    # ohc_x = encode_filler(ohc_x)\n",
    "    processed_x = pd.concat([scaled_x, ohc_x], axis=1)\n",
    "\n",
    "    # GridSearch CV\n",
    "    param_grid = {\n",
    "        'C': [0.5, 1, 10],\n",
    "        'gamma': ['scale', 0.1, 0.01],\n",
    "        'kernel': ['rbf']\n",
    "    }\n",
    "\n",
    "    optimal_params = GridSearchCV(SVC(probability=True, random_state=42), param_grid, n_jobs=-1, cv=5, scoring='neg_log_loss')\n",
    "    \n",
    "    # Fit the model\n",
    "    optimal_params.fit(processed_x, y)\n",
    "    print(\"best score: \", optimal_params.best_score_)\n",
    "\n",
    "    #Save the results to csv file\n",
    "    results = optimal_params.cv_results_\n",
    "    log_loss_scores = results['mean_test_score']  # Mean log loss (negative)\n",
    "    hyperparameters = results['params'] \n",
    "    results_df = pd.DataFrame(hyperparameters)\n",
    "    results_df['Mean Log Loss'] = -log_loss_scores  # Convert back to positive (lower is better)\n",
    "\n",
    "    # Display the results sorted by Log Loss\n",
    "    results_df = results_df.sort_values(by='Mean Log Loss', ascending=True)\n",
    "    results_df.to_csv(os.path.join(RESULT_DATA_DIR, \"svm_scaler_filled.csv\"), index=False)\n",
    "\n",
    "    return optimal_params.best_estimator_, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score:  -1.9566210198631904\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(os.path.join(MODEL_TRAINING_DATA_DIR, \"TRAIN_MERGED_UNFILLED_encoded.csv\"))\n",
    "\n",
    "train_A, train_B = train_test_split(train_data, test_size=0.25, stratify=train_data['subjectivePoverty_rating'], random_state=42)\n",
    "\n",
    "model, scaler= predict_ratings_SVM(train_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = result[0]\n",
    "scaler = result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9525670441687637\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psu_hh_idcode</th>\n",
       "      <th>subjective_poverty1</th>\n",
       "      <th>subjective_poverty2</th>\n",
       "      <th>subjective_poverty3</th>\n",
       "      <th>subjective_poverty4</th>\n",
       "      <th>subjective_poverty5</th>\n",
       "      <th>subjective_poverty6</th>\n",
       "      <th>subjective_poverty7</th>\n",
       "      <th>subjective_poverty8</th>\n",
       "      <th>subjective_poverty9</th>\n",
       "      <th>subjective_poverty10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125_11_1</td>\n",
       "      <td>0.042326</td>\n",
       "      <td>0.100207</td>\n",
       "      <td>0.198878</td>\n",
       "      <td>0.220306</td>\n",
       "      <td>0.190766</td>\n",
       "      <td>0.131592</td>\n",
       "      <td>0.074284</td>\n",
       "      <td>0.032160</td>\n",
       "      <td>0.007809</td>\n",
       "      <td>0.001672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129_9_1</td>\n",
       "      <td>0.034815</td>\n",
       "      <td>0.089819</td>\n",
       "      <td>0.148711</td>\n",
       "      <td>0.215838</td>\n",
       "      <td>0.219608</td>\n",
       "      <td>0.163542</td>\n",
       "      <td>0.078356</td>\n",
       "      <td>0.038659</td>\n",
       "      <td>0.008513</td>\n",
       "      <td>0.002139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>800_8_1</td>\n",
       "      <td>0.030884</td>\n",
       "      <td>0.066006</td>\n",
       "      <td>0.142376</td>\n",
       "      <td>0.212844</td>\n",
       "      <td>0.217293</td>\n",
       "      <td>0.167825</td>\n",
       "      <td>0.097959</td>\n",
       "      <td>0.051879</td>\n",
       "      <td>0.011014</td>\n",
       "      <td>0.001920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>472_1_1</td>\n",
       "      <td>0.028243</td>\n",
       "      <td>0.059863</td>\n",
       "      <td>0.091540</td>\n",
       "      <td>0.176005</td>\n",
       "      <td>0.227839</td>\n",
       "      <td>0.200532</td>\n",
       "      <td>0.132426</td>\n",
       "      <td>0.065874</td>\n",
       "      <td>0.013144</td>\n",
       "      <td>0.004533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>309_11_1</td>\n",
       "      <td>0.036398</td>\n",
       "      <td>0.101143</td>\n",
       "      <td>0.176531</td>\n",
       "      <td>0.214061</td>\n",
       "      <td>0.219556</td>\n",
       "      <td>0.133580</td>\n",
       "      <td>0.075188</td>\n",
       "      <td>0.033903</td>\n",
       "      <td>0.008071</td>\n",
       "      <td>0.001568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>588_5_1</td>\n",
       "      <td>0.041144</td>\n",
       "      <td>0.092536</td>\n",
       "      <td>0.176661</td>\n",
       "      <td>0.219909</td>\n",
       "      <td>0.210417</td>\n",
       "      <td>0.136500</td>\n",
       "      <td>0.079856</td>\n",
       "      <td>0.033037</td>\n",
       "      <td>0.008334</td>\n",
       "      <td>0.001606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>566_4_1</td>\n",
       "      <td>0.033879</td>\n",
       "      <td>0.088505</td>\n",
       "      <td>0.178952</td>\n",
       "      <td>0.208840</td>\n",
       "      <td>0.209351</td>\n",
       "      <td>0.152723</td>\n",
       "      <td>0.077726</td>\n",
       "      <td>0.038333</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.002880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>220_7_1</td>\n",
       "      <td>0.035826</td>\n",
       "      <td>0.083817</td>\n",
       "      <td>0.156081</td>\n",
       "      <td>0.212037</td>\n",
       "      <td>0.217032</td>\n",
       "      <td>0.159349</td>\n",
       "      <td>0.087401</td>\n",
       "      <td>0.037977</td>\n",
       "      <td>0.008284</td>\n",
       "      <td>0.002197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>144_5_2</td>\n",
       "      <td>0.034504</td>\n",
       "      <td>0.057781</td>\n",
       "      <td>0.137760</td>\n",
       "      <td>0.156903</td>\n",
       "      <td>0.195478</td>\n",
       "      <td>0.166863</td>\n",
       "      <td>0.134209</td>\n",
       "      <td>0.098464</td>\n",
       "      <td>0.015511</td>\n",
       "      <td>0.002527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>18_7_1</td>\n",
       "      <td>0.038029</td>\n",
       "      <td>0.082840</td>\n",
       "      <td>0.183488</td>\n",
       "      <td>0.207353</td>\n",
       "      <td>0.209293</td>\n",
       "      <td>0.129007</td>\n",
       "      <td>0.088944</td>\n",
       "      <td>0.050670</td>\n",
       "      <td>0.008580</td>\n",
       "      <td>0.001796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1334 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     psu_hh_idcode  subjective_poverty1  subjective_poverty2  \\\n",
       "0         125_11_1             0.042326             0.100207   \n",
       "1          129_9_1             0.034815             0.089819   \n",
       "2          800_8_1             0.030884             0.066006   \n",
       "3          472_1_1             0.028243             0.059863   \n",
       "4         309_11_1             0.036398             0.101143   \n",
       "...            ...                  ...                  ...   \n",
       "1329       588_5_1             0.041144             0.092536   \n",
       "1330       566_4_1             0.033879             0.088505   \n",
       "1331       220_7_1             0.035826             0.083817   \n",
       "1332       144_5_2             0.034504             0.057781   \n",
       "1333        18_7_1             0.038029             0.082840   \n",
       "\n",
       "      subjective_poverty3  subjective_poverty4  subjective_poverty5  \\\n",
       "0                0.198878             0.220306             0.190766   \n",
       "1                0.148711             0.215838             0.219608   \n",
       "2                0.142376             0.212844             0.217293   \n",
       "3                0.091540             0.176005             0.227839   \n",
       "4                0.176531             0.214061             0.219556   \n",
       "...                   ...                  ...                  ...   \n",
       "1329             0.176661             0.219909             0.210417   \n",
       "1330             0.178952             0.208840             0.209351   \n",
       "1331             0.156081             0.212037             0.217032   \n",
       "1332             0.137760             0.156903             0.195478   \n",
       "1333             0.183488             0.207353             0.209293   \n",
       "\n",
       "      subjective_poverty6  subjective_poverty7  subjective_poverty8  \\\n",
       "0                0.131592             0.074284             0.032160   \n",
       "1                0.163542             0.078356             0.038659   \n",
       "2                0.167825             0.097959             0.051879   \n",
       "3                0.200532             0.132426             0.065874   \n",
       "4                0.133580             0.075188             0.033903   \n",
       "...                   ...                  ...                  ...   \n",
       "1329             0.136500             0.079856             0.033037   \n",
       "1330             0.152723             0.077726             0.038333   \n",
       "1331             0.159349             0.087401             0.037977   \n",
       "1332             0.166863             0.134209             0.098464   \n",
       "1333             0.129007             0.088944             0.050670   \n",
       "\n",
       "      subjective_poverty9  subjective_poverty10  \n",
       "0                0.007809              0.001672  \n",
       "1                0.008513              0.002139  \n",
       "2                0.011014              0.001920  \n",
       "3                0.013144              0.004533  \n",
       "4                0.008071              0.001568  \n",
       "...                   ...                   ...  \n",
       "1329             0.008334              0.001606  \n",
       "1330             0.008811              0.002880  \n",
       "1331             0.008284              0.002197  \n",
       "1332             0.015511              0.002527  \n",
       "1333             0.008580              0.001796  \n",
       "\n",
       "[1334 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_B_X = train_B.drop(columns=['subjectivePoverty_rating'])\n",
    "# display(train_B_X)\n",
    "\n",
    "def predictratings_SVM(model, scaler, train_B_X):\n",
    "    test_ids = train_B_X['psu_hh_idcode']\n",
    "\n",
    "    # Scale ordinal and numerical data\n",
    "    ordinal_col = ['q23', 'Q06']\n",
    "    numerical_col = ['q05', 'q09', 'Q07']\n",
    "    scalable_col = ordinal_col + numerical_col\n",
    "\n",
    "    scalable_x = train_B_X[scalable_col]\n",
    "\n",
    "    scaled_x = scaler.transform(scalable_x)\n",
    "    scaled_x = pd.DataFrame(scaled_x, columns=scalable_x.columns, index=scalable_x.index)\n",
    "\n",
    "    # One-hot-encoding\n",
    "    ohc_col = ['q02', 'q03_1', 'q03_2', 'q03_3', 'q03_4', 'q03_5', 'q03_6', 'q03_7', 'q03_8', 'q03_9', 'q03_10',\n",
    "    'q03_11', 'q03_12', 'q03_13', 'q03_14', 'Q03', 'Q08', 'Q11_1', 'Q11_2', 'Q11_3', 'Q11_4',\n",
    "    'Q11_5', 'Q11_6', 'Q11_7', 'Q11_8', 'Q11_9', 'Q11_10', 'Q11_11', 'Q11_12', 'Q11_13', 'Q19',\n",
    "    'Q01_0', 'Q01_1', 'Q01_2']\n",
    "\n",
    "    ohc_x = train_B_X[ohc_col]\n",
    "    processed_x = pd.concat([scaled_x, ohc_x], axis=1)\n",
    "\n",
    "\n",
    "    preds_proba = model.predict_proba(processed_x)\n",
    "    print(log_loss(train_B['subjectivePoverty_rating'], preds_proba))\n",
    "    output_df = pd.DataFrame(preds_proba, columns=[f'subjective_poverty{i+1}' for i in range(preds_proba.shape[1])])\n",
    "    output_df.insert(0, 'psu_hh_idcode', test_ids.values)  # Insert the ID column at the start\n",
    "    return output_df\n",
    "\n",
    "pred = predictratings_SVM(model, scaler, train_B_X)\n",
    "display(pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "psu_hh_idcode\tsubjective_poverty1\tsubjective_poverty2\tsubjective_poverty3\tsubjective_poverty4\tsubjective_poverty5\tsubjective_poverty6\tsubjective_poverty7\tsubjective_poverty8\tsubjective_poverty9\tsubjective_poverty10\n",
    "0\t125_11_1\t0.025525\t0.059814\t0.087623\t0.220639\t0.233748\t0.182541\t0.121753\t0.053184\t0.011969\t0.003203\n",
    "1\t129_9_1\t0.037075\t0.058612\t0.088723\t0.214832\t0.184983\t0.169812\t0.163631\t0.064149\t0.014398\t0.003784\n",
    "2\t800_8_1\t0.027463\t0.057546\t0.080168\t0.217410\t0.228223\t0.184984\t0.132869\t0.054868\t0.012673\t0.003796\n",
    "3\t472_1_1\t0.034906\t0.057764\t0.085594\t0.217024\t0.193675\t0.172937\t0.157929\t0.062606\t0.014007\t0.003559\n",
    "4\t309_11_1\t0.027289\t0.057630\t0.078263\t0.222137\t0.226802\t0.182085\t0.132389\t0.057131\t0.012434\t0.003839\n",
    "...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\n",
    "1329\t588_5_1\t0.026330\t0.058408\t0.083609\t0.219034\t0.233413\t0.183294\t0.125962\t0.054159\t0.012287\t0.003504\n",
    "1330\t566_4_1\t0.036910\t0.058539\t0.088463\t0.214998\t0.185711\t0.170098\t0.163133\t0.064025\t0.014363\t0.003761\n",
    "1331\t220_7_1\t0.031674\t0.057190\t0.081302\t0.220262\t0.208272\t0.177602\t0.146896\t0.059892\t0.013415\t0.003495\n",
    "1332\t144_5_2\t0.024264\t0.065964\t0.090802\t0.210098\t0.245841\t0.185363\t0.109233\t0.054836\t0.011278\t0.002322\n",
    "1333\t18_7_1\t0.034787\t0.057585\t0.085540\t0.217065\t0.194416\t0.173364\t0.157189\t0.062621\t0.013908\t0.003525\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
