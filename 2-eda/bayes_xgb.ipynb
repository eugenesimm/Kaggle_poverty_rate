{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import log_loss\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "import xgboost as xgb\n",
    "MODEL_TRAINING_DATA_DIR = \"../data/model_training/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ratings_XGB(model, train_B_X):\n",
    "    test_ids = train_B_X['psu_hh_idcode']\n",
    "    sp = train_B_X['subjectivePoverty_rating']\n",
    "    train_B_X = train_B_X.drop(columns=['psu_hh_idcode', 'subjectivePoverty_rating'])\n",
    "    preds_proba = model.predict_proba(train_B_X)\n",
    "    print(log_loss(sp, preds_proba))\n",
    "    output_df = pd.DataFrame(preds_proba, columns=[f'subjective_poverty_{i+1}' for i in range(preds_proba.shape[1])])\n",
    "    output_df.insert(0, 'psu_hh_idcode', test_ids.values)  # Insert the ID column at the start\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_best_XGB_model_bayesian(train_data):\n",
    "\n",
    "    # Prepare training data\n",
    "    X_train = train_data.drop(columns=['psu_hh_idcode', 'subjectivePoverty_rating'], axis='columns')\n",
    "    y_train = train_data['subjectivePoverty_rating'] - 1\n",
    "    \n",
    "    # Split into training and validation sets for Bayesian Optimization\n",
    "    X_train_bayes, X_val, y_train_bayes, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=42)\n",
    "    \n",
    "    # Define the objective function for Bayesian Optimization\n",
    "    def xgb_evaluate(learning_rate, max_depth, n_estimators, gamma, colsample_bytree, subsample, eta, reg_lambda, reg_alpha, min_child_weight):\n",
    "        params = {\n",
    "            'learning_rate': learning_rate,\n",
    "            'max_depth': int(max_depth),  # Must be an integer\n",
    "            'gamma': gamma,\n",
    "            'colsample_bytree': colsample_bytree,\n",
    "            'subsample': subsample,\n",
    "            'eta': eta,\n",
    "            'objective': 'multi:softprob',\n",
    "            'num_class': len(np.unique(y_train)),\n",
    "            'eval_metric': 'mlogloss',\n",
    "            'reg_lambda': reg_lambda,\n",
    "            'reg_alpha': reg_alpha,\n",
    "             'min_child_weight': min_child_weight,\n",
    "            'use_label_encoder': False,\n",
    "            'verbosity': 0,\n",
    "            'random_state': 42,\n",
    "            'n_estimators': int(n_estimators),\n",
    "        }\n",
    "        \n",
    "        model = xgb.XGBClassifier(**params)\n",
    "        model.fit(X_train_bayes, y_train_bayes, eval_set=[(X_val, y_val)], verbose=False)\n",
    "        y_pred = model.predict_proba(X_val)\n",
    "        return -log_loss(y_val, y_pred)  # Negative log loss (BayesianOptimization maximizes the function)\n",
    "    \n",
    "    # Define the bounds for hyperparameters\n",
    "    param_bounds = {\n",
    "        'learning_rate': (0.01, 0.3),\n",
    "        'max_depth': (3, 10),\n",
    "        'n_estimators': (100, 500),\n",
    "        'subsample': (0.5, 1.0),\n",
    "        'colsample_bytree': (0.5, 1.0),\n",
    "        'gamma': (0, 0.5),\n",
    "        'reg_alpha': (0, 1),\n",
    "        'reg_lambda': (0.1, 10),\n",
    "        'min_child_weight': (1, 5),\n",
    "        'eta': (0.01, 0.2)\n",
    "    }\n",
    "    \n",
    "    # Initialize Bayesian Optimizer\n",
    "    optimizer = BayesianOptimization(f=xgb_evaluate, pbounds=param_bounds, random_state=42, verbose=2)\n",
    "    \n",
    "    # Maximize the objective function\n",
    "    optimizer.maximize(init_points=10, n_iter=30)\n",
    "\n",
    "    best_params = optimizer.max['params']\n",
    "    best_params['max_depth'] = int(best_params['max_depth'])\n",
    "    best_params['n_estimators'] = int(best_params['n_estimators'])\n",
    "\n",
    "    best_model_xgb = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        eval_metric='mlogloss',\n",
    "        use_label_encoder=False,\n",
    "        random_state=42,\n",
    "        **best_params\n",
    "    )\n",
    "\n",
    "    best_model_xgb.fit(X_train, y_train)\n",
    "\n",
    "    return best_model_xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |    eta    |   gamma   | learni... | max_depth | min_ch... | n_esti... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m train_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/model_training/TRAIN_MERGED_UNFILLED_encoded.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# FILLED OR UNFILLED\u001b[39;00m\n\u001b[1;32m      2\u001b[0m train_A, train_B \u001b[38;5;241m=\u001b[39m train_test_split(train_data, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, stratify\u001b[38;5;241m=\u001b[39mtrain_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubjectivePoverty_rating\u001b[39m\u001b[38;5;124m'\u001b[39m], random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_best_XGB_model_bayesian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_A\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 54\u001b[0m, in \u001b[0;36mgenerate_best_XGB_model_bayesian\u001b[0;34m(train_data)\u001b[0m\n\u001b[1;32m     51\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m BayesianOptimization(f\u001b[38;5;241m=\u001b[39mxgb_evaluate, pbounds\u001b[38;5;241m=\u001b[39mparam_bounds, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Maximize the objective function\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m best_params \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mmax[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     57\u001b[0m best_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(best_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/bayes_opt/bayesian_optimization.py:303\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[0;34m(self, init_points, n_iter)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prime_subscriptions()\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch(Events\u001b[38;5;241m.\u001b[39mOPTIMIZATION_START)\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prime_queue\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_points\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue \u001b[38;5;129;01mor\u001b[39;00m iteration \u001b[38;5;241m<\u001b[39m n_iter:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/bayes_opt/bayesian_optimization.py:270\u001b[0m, in \u001b[0;36mBayesianOptimization._prime_queue\u001b[0;34m(self, init_points)\u001b[0m\n\u001b[1;32m    267\u001b[0m     init_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(init_points, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(init_points):\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/bayes_opt/target_space.py:446\u001b[0m, in \u001b[0;36mTargetSpace.random_sample\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;124;03mSample a random point from within the bounds of the space.\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03marray([[ 0.54488318,   55.33253689]])\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    445\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim))\n\u001b[0;32m--> 446\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col, (lower, upper) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds):\n\u001b[1;32m    447\u001b[0m     data\u001b[38;5;241m.\u001b[39mT[col] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\u001b[38;5;241m.\u001b[39muniform(lower, upper, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\u001b[38;5;241m.\u001b[39mravel()\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"../data/model_training/TRAIN_MERGED_UNFILLED_encoded.csv\") # FILLED OR UNFILLED\n",
    "train_A, train_B = train_test_split(train_data, test_size=0.25, stratify=train_data['subjectivePoverty_rating'], random_state=42)\n",
    "xgb_model = generate_best_XGB_model_bayesian(train_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9448122734844189\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psu_hh_idcode</th>\n",
       "      <th>subjective_poverty_1</th>\n",
       "      <th>subjective_poverty_2</th>\n",
       "      <th>subjective_poverty_3</th>\n",
       "      <th>subjective_poverty_4</th>\n",
       "      <th>subjective_poverty_5</th>\n",
       "      <th>subjective_poverty_6</th>\n",
       "      <th>subjective_poverty_7</th>\n",
       "      <th>subjective_poverty_8</th>\n",
       "      <th>subjective_poverty_9</th>\n",
       "      <th>subjective_poverty_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125_11_1</td>\n",
       "      <td>0.053198</td>\n",
       "      <td>0.147047</td>\n",
       "      <td>0.205009</td>\n",
       "      <td>0.227987</td>\n",
       "      <td>0.166126</td>\n",
       "      <td>0.101554</td>\n",
       "      <td>0.053130</td>\n",
       "      <td>0.029398</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>0.006770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129_9_1</td>\n",
       "      <td>0.037607</td>\n",
       "      <td>0.095309</td>\n",
       "      <td>0.125541</td>\n",
       "      <td>0.204742</td>\n",
       "      <td>0.234721</td>\n",
       "      <td>0.175700</td>\n",
       "      <td>0.067691</td>\n",
       "      <td>0.039480</td>\n",
       "      <td>0.011303</td>\n",
       "      <td>0.007906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>800_8_1</td>\n",
       "      <td>0.024932</td>\n",
       "      <td>0.062987</td>\n",
       "      <td>0.134589</td>\n",
       "      <td>0.238510</td>\n",
       "      <td>0.202400</td>\n",
       "      <td>0.162890</td>\n",
       "      <td>0.100470</td>\n",
       "      <td>0.046250</td>\n",
       "      <td>0.020191</td>\n",
       "      <td>0.006780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>472_1_1</td>\n",
       "      <td>0.017377</td>\n",
       "      <td>0.033107</td>\n",
       "      <td>0.073200</td>\n",
       "      <td>0.158520</td>\n",
       "      <td>0.204500</td>\n",
       "      <td>0.161609</td>\n",
       "      <td>0.145780</td>\n",
       "      <td>0.174740</td>\n",
       "      <td>0.024756</td>\n",
       "      <td>0.006410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>309_11_1</td>\n",
       "      <td>0.024061</td>\n",
       "      <td>0.070031</td>\n",
       "      <td>0.145830</td>\n",
       "      <td>0.235331</td>\n",
       "      <td>0.270069</td>\n",
       "      <td>0.124617</td>\n",
       "      <td>0.079546</td>\n",
       "      <td>0.034306</td>\n",
       "      <td>0.009698</td>\n",
       "      <td>0.006510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>588_5_1</td>\n",
       "      <td>0.073820</td>\n",
       "      <td>0.132011</td>\n",
       "      <td>0.184935</td>\n",
       "      <td>0.209218</td>\n",
       "      <td>0.176477</td>\n",
       "      <td>0.114375</td>\n",
       "      <td>0.066254</td>\n",
       "      <td>0.026385</td>\n",
       "      <td>0.009803</td>\n",
       "      <td>0.006724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>566_4_1</td>\n",
       "      <td>0.031436</td>\n",
       "      <td>0.079376</td>\n",
       "      <td>0.213136</td>\n",
       "      <td>0.204183</td>\n",
       "      <td>0.209229</td>\n",
       "      <td>0.167167</td>\n",
       "      <td>0.052214</td>\n",
       "      <td>0.025665</td>\n",
       "      <td>0.010352</td>\n",
       "      <td>0.007241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>220_7_1</td>\n",
       "      <td>0.023395</td>\n",
       "      <td>0.067403</td>\n",
       "      <td>0.134976</td>\n",
       "      <td>0.206999</td>\n",
       "      <td>0.200921</td>\n",
       "      <td>0.191419</td>\n",
       "      <td>0.116847</td>\n",
       "      <td>0.040777</td>\n",
       "      <td>0.010424</td>\n",
       "      <td>0.006840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>144_5_2</td>\n",
       "      <td>0.042511</td>\n",
       "      <td>0.031137</td>\n",
       "      <td>0.173549</td>\n",
       "      <td>0.118494</td>\n",
       "      <td>0.187920</td>\n",
       "      <td>0.209207</td>\n",
       "      <td>0.119438</td>\n",
       "      <td>0.079145</td>\n",
       "      <td>0.031575</td>\n",
       "      <td>0.007025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>18_7_1</td>\n",
       "      <td>0.034099</td>\n",
       "      <td>0.084631</td>\n",
       "      <td>0.261025</td>\n",
       "      <td>0.230935</td>\n",
       "      <td>0.192638</td>\n",
       "      <td>0.099112</td>\n",
       "      <td>0.053563</td>\n",
       "      <td>0.025347</td>\n",
       "      <td>0.011723</td>\n",
       "      <td>0.006928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1334 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     psu_hh_idcode  subjective_poverty_1  subjective_poverty_2  \\\n",
       "0         125_11_1              0.053198              0.147047   \n",
       "1          129_9_1              0.037607              0.095309   \n",
       "2          800_8_1              0.024932              0.062987   \n",
       "3          472_1_1              0.017377              0.033107   \n",
       "4         309_11_1              0.024061              0.070031   \n",
       "...            ...                   ...                   ...   \n",
       "1329       588_5_1              0.073820              0.132011   \n",
       "1330       566_4_1              0.031436              0.079376   \n",
       "1331       220_7_1              0.023395              0.067403   \n",
       "1332       144_5_2              0.042511              0.031137   \n",
       "1333        18_7_1              0.034099              0.084631   \n",
       "\n",
       "      subjective_poverty_3  subjective_poverty_4  subjective_poverty_5  \\\n",
       "0                 0.205009              0.227987              0.166126   \n",
       "1                 0.125541              0.204742              0.234721   \n",
       "2                 0.134589              0.238510              0.202400   \n",
       "3                 0.073200              0.158520              0.204500   \n",
       "4                 0.145830              0.235331              0.270069   \n",
       "...                    ...                   ...                   ...   \n",
       "1329              0.184935              0.209218              0.176477   \n",
       "1330              0.213136              0.204183              0.209229   \n",
       "1331              0.134976              0.206999              0.200921   \n",
       "1332              0.173549              0.118494              0.187920   \n",
       "1333              0.261025              0.230935              0.192638   \n",
       "\n",
       "      subjective_poverty_6  subjective_poverty_7  subjective_poverty_8  \\\n",
       "0                 0.101554              0.053130              0.029398   \n",
       "1                 0.175700              0.067691              0.039480   \n",
       "2                 0.162890              0.100470              0.046250   \n",
       "3                 0.161609              0.145780              0.174740   \n",
       "4                 0.124617              0.079546              0.034306   \n",
       "...                    ...                   ...                   ...   \n",
       "1329              0.114375              0.066254              0.026385   \n",
       "1330              0.167167              0.052214              0.025665   \n",
       "1331              0.191419              0.116847              0.040777   \n",
       "1332              0.209207              0.119438              0.079145   \n",
       "1333              0.099112              0.053563              0.025347   \n",
       "\n",
       "      subjective_poverty_9  subjective_poverty_10  \n",
       "0                 0.009781               0.006770  \n",
       "1                 0.011303               0.007906  \n",
       "2                 0.020191               0.006780  \n",
       "3                 0.024756               0.006410  \n",
       "4                 0.009698               0.006510  \n",
       "...                    ...                    ...  \n",
       "1329              0.009803               0.006724  \n",
       "1330              0.010352               0.007241  \n",
       "1331              0.010424               0.006840  \n",
       "1332              0.031575               0.007025  \n",
       "1333              0.011723               0.006928  \n",
       "\n",
       "[1334 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train_B_X = train_B.drop(columns=['subjectivePoverty_rating'])\n",
    "pred = predict_ratings_XGB(xgb_model, train_B)\n",
    "display(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
