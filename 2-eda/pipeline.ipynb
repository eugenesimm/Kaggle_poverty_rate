{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import log_loss, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "CLEAN_DATA_DIR = \"../data/clean/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(data):\n",
    "  col = [col for col in data.columns if -1 in data[col].values]\n",
    "  # One-hot encode categorical columns\n",
    "  encoder = OneHotEncoder(sparse_output=False, drop=None)\n",
    "  encoded = encoder.fit_transform(data[col])\n",
    "\n",
    "  # Convert to DataFrame and combine with numerical features\n",
    "  encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(col), index=data.index)\n",
    "  numerical_df = data.drop(columns=col)\n",
    "\n",
    "  # Combine numerical and encoded categorical data\n",
    "  processed_df = pd.concat([numerical_df, encoded_df], axis=1)\n",
    "  return processed_df\n",
    "\n",
    "\n",
    "def encode_filler(data):\n",
    "  na_col = ['Q11_5.0', 'Q11_9.0', 'Q11_14.0',\n",
    "              'Q11_2.0', 'Q08_-1.0', 'Q08_2.0', 'q02', 'Q11_3.0', 'Q03',\n",
    "              'Q11_4.0', 'Q11_7.0', 'Q11_13.0', 'Q19_2.0', 'Q11_-1.0', 'Q11_10.0',\n",
    "              'Q11_12.0', 'Q19_-1.0',  'Q11_1.0', 'Q19_1.0', 'Q11_8.0', 'Q08_1.0',  'q03',\n",
    "               'Q11_11.0', ]\n",
    "\n",
    "  for col in na_col:\n",
    "      if col not in data.columns:\n",
    "          data[col] = 0  # Assign 0\n",
    "  \n",
    "  filled_data = data[na_col]\n",
    "  return filled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ratings_SVM(train_data):\n",
    "\n",
    "    train_x = train_data.drop(columns=['psu_hh_idcode', 'subjectivePoverty_rating'])\n",
    "    # # Combine numerical and encoded categorical data\n",
    "    # processed_train = encoder(train_x)\n",
    "    # processed_train = encode_filler(processed_train)\n",
    "\n",
    "    y = train_data['subjectivePoverty_rating']\n",
    "    # X = processed_train\n",
    "\n",
    "    ordinal_col = ['q23', 'Q01', 'Q06']\n",
    "    numerical_col = ['q05', 'q09', 'Q07']\n",
    "    binary_col = ['q02', 'q03', 'Q03', 'Q08', 'Q11', 'Q19']\n",
    "\n",
    "    # Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_col),    # Scale numerical features\n",
    "            ('ord', StandardScaler(), ordinal_col),      # Scale ordinal categorical features\n",
    "            ('one_hot', 'passthrough', binary_col)      # Leave one-hot-encoded features unchanged\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Complete pipeline with SVM\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', SVC(probability=True, random_state=42))\n",
    "    ])\n",
    "    \n",
    "   # GridSearch CV\n",
    "    param_grid = {\n",
    "        'classifier__C': [0.5, 1, 10, 100],\n",
    "        'classifier__gamma': ['scale', 0.1, 0.01, 0.001],\n",
    "        'classifier__kernel': ['rbf']\n",
    "    }\n",
    "\n",
    "    optimal_params = GridSearchCV(pipeline, param_grid, n_jobs=-1, cv=5, scoring='neg_log_loss', verbose=1)\n",
    "    \n",
    "    # Fit the model\n",
    "    optimal_params.fit(train_x, y)\n",
    "    return optimal_params.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    }
   ],
   "source": [
    "RESULT_DATA_DIR = \"../data/model_result/\"\n",
    "train_data = pd.read_csv(os.path.join(CLEAN_DATA_DIR, \"TRAIN_MERGED_UNFILLED.csv\"))\n",
    "\n",
    "train_A, train_B = train_test_split(train_data, test_size=0.25, stratify=train_data['subjectivePoverty_rating'], random_state=42)\n",
    "\n",
    "model = predict_ratings_SVM(train_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['q02', 'q03', 'q05', 'q09', 'q23', 'Q01', 'Q03']\n",
    "['q02', 'q03', 'q05', 'q09', 'q23', 'Q01', 'Q03']\n",
    "['q02', 'q03', 'q05', 'q09', 'q23', 'Q01', 'Q03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9533630140413727\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psu_hh_idcode</th>\n",
       "      <th>subjective_poverty1</th>\n",
       "      <th>subjective_poverty2</th>\n",
       "      <th>subjective_poverty3</th>\n",
       "      <th>subjective_poverty4</th>\n",
       "      <th>subjective_poverty5</th>\n",
       "      <th>subjective_poverty6</th>\n",
       "      <th>subjective_poverty7</th>\n",
       "      <th>subjective_poverty8</th>\n",
       "      <th>subjective_poverty9</th>\n",
       "      <th>subjective_poverty10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125_11_1</td>\n",
       "      <td>0.039803</td>\n",
       "      <td>0.093217</td>\n",
       "      <td>0.182597</td>\n",
       "      <td>0.224901</td>\n",
       "      <td>0.204218</td>\n",
       "      <td>0.137551</td>\n",
       "      <td>0.075938</td>\n",
       "      <td>0.031804</td>\n",
       "      <td>0.007923</td>\n",
       "      <td>0.002049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129_9_1</td>\n",
       "      <td>0.033954</td>\n",
       "      <td>0.089941</td>\n",
       "      <td>0.156894</td>\n",
       "      <td>0.213108</td>\n",
       "      <td>0.213700</td>\n",
       "      <td>0.161301</td>\n",
       "      <td>0.077689</td>\n",
       "      <td>0.042275</td>\n",
       "      <td>0.008087</td>\n",
       "      <td>0.003051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>800_8_1</td>\n",
       "      <td>0.031121</td>\n",
       "      <td>0.068129</td>\n",
       "      <td>0.157122</td>\n",
       "      <td>0.217648</td>\n",
       "      <td>0.209474</td>\n",
       "      <td>0.160807</td>\n",
       "      <td>0.091368</td>\n",
       "      <td>0.052482</td>\n",
       "      <td>0.010940</td>\n",
       "      <td>0.000910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>472_1_1</td>\n",
       "      <td>0.029062</td>\n",
       "      <td>0.058346</td>\n",
       "      <td>0.091228</td>\n",
       "      <td>0.168264</td>\n",
       "      <td>0.231946</td>\n",
       "      <td>0.205058</td>\n",
       "      <td>0.130607</td>\n",
       "      <td>0.066442</td>\n",
       "      <td>0.013639</td>\n",
       "      <td>0.005408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>309_11_1</td>\n",
       "      <td>0.038624</td>\n",
       "      <td>0.090862</td>\n",
       "      <td>0.174254</td>\n",
       "      <td>0.213264</td>\n",
       "      <td>0.210572</td>\n",
       "      <td>0.144435</td>\n",
       "      <td>0.082904</td>\n",
       "      <td>0.036531</td>\n",
       "      <td>0.007472</td>\n",
       "      <td>0.001081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>588_5_1</td>\n",
       "      <td>0.042078</td>\n",
       "      <td>0.088893</td>\n",
       "      <td>0.178973</td>\n",
       "      <td>0.222101</td>\n",
       "      <td>0.200386</td>\n",
       "      <td>0.140713</td>\n",
       "      <td>0.081242</td>\n",
       "      <td>0.036272</td>\n",
       "      <td>0.008636</td>\n",
       "      <td>0.000706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>566_4_1</td>\n",
       "      <td>0.034969</td>\n",
       "      <td>0.089865</td>\n",
       "      <td>0.176643</td>\n",
       "      <td>0.213351</td>\n",
       "      <td>0.199546</td>\n",
       "      <td>0.150787</td>\n",
       "      <td>0.081267</td>\n",
       "      <td>0.040948</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>0.003736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>220_7_1</td>\n",
       "      <td>0.036896</td>\n",
       "      <td>0.086409</td>\n",
       "      <td>0.161406</td>\n",
       "      <td>0.207002</td>\n",
       "      <td>0.211835</td>\n",
       "      <td>0.156614</td>\n",
       "      <td>0.086781</td>\n",
       "      <td>0.041645</td>\n",
       "      <td>0.008455</td>\n",
       "      <td>0.002959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>144_5_2</td>\n",
       "      <td>0.036821</td>\n",
       "      <td>0.065292</td>\n",
       "      <td>0.133330</td>\n",
       "      <td>0.202747</td>\n",
       "      <td>0.202078</td>\n",
       "      <td>0.168880</td>\n",
       "      <td>0.115258</td>\n",
       "      <td>0.064309</td>\n",
       "      <td>0.010154</td>\n",
       "      <td>0.001129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>18_7_1</td>\n",
       "      <td>0.039036</td>\n",
       "      <td>0.091626</td>\n",
       "      <td>0.193118</td>\n",
       "      <td>0.216226</td>\n",
       "      <td>0.200676</td>\n",
       "      <td>0.121580</td>\n",
       "      <td>0.084480</td>\n",
       "      <td>0.044604</td>\n",
       "      <td>0.007039</td>\n",
       "      <td>0.001615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1334 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     psu_hh_idcode  subjective_poverty1  subjective_poverty2  \\\n",
       "0         125_11_1             0.039803             0.093217   \n",
       "1          129_9_1             0.033954             0.089941   \n",
       "2          800_8_1             0.031121             0.068129   \n",
       "3          472_1_1             0.029062             0.058346   \n",
       "4         309_11_1             0.038624             0.090862   \n",
       "...            ...                  ...                  ...   \n",
       "1329       588_5_1             0.042078             0.088893   \n",
       "1330       566_4_1             0.034969             0.089865   \n",
       "1331       220_7_1             0.036896             0.086409   \n",
       "1332       144_5_2             0.036821             0.065292   \n",
       "1333        18_7_1             0.039036             0.091626   \n",
       "\n",
       "      subjective_poverty3  subjective_poverty4  subjective_poverty5  \\\n",
       "0                0.182597             0.224901             0.204218   \n",
       "1                0.156894             0.213108             0.213700   \n",
       "2                0.157122             0.217648             0.209474   \n",
       "3                0.091228             0.168264             0.231946   \n",
       "4                0.174254             0.213264             0.210572   \n",
       "...                   ...                  ...                  ...   \n",
       "1329             0.178973             0.222101             0.200386   \n",
       "1330             0.176643             0.213351             0.199546   \n",
       "1331             0.161406             0.207002             0.211835   \n",
       "1332             0.133330             0.202747             0.202078   \n",
       "1333             0.193118             0.216226             0.200676   \n",
       "\n",
       "      subjective_poverty6  subjective_poverty7  subjective_poverty8  \\\n",
       "0                0.137551             0.075938             0.031804   \n",
       "1                0.161301             0.077689             0.042275   \n",
       "2                0.160807             0.091368             0.052482   \n",
       "3                0.205058             0.130607             0.066442   \n",
       "4                0.144435             0.082904             0.036531   \n",
       "...                   ...                  ...                  ...   \n",
       "1329             0.140713             0.081242             0.036272   \n",
       "1330             0.150787             0.081267             0.040948   \n",
       "1331             0.156614             0.086781             0.041645   \n",
       "1332             0.168880             0.115258             0.064309   \n",
       "1333             0.121580             0.084480             0.044604   \n",
       "\n",
       "      subjective_poverty9  subjective_poverty10  \n",
       "0                0.007923              0.002049  \n",
       "1                0.008087              0.003051  \n",
       "2                0.010940              0.000910  \n",
       "3                0.013639              0.005408  \n",
       "4                0.007472              0.001081  \n",
       "...                   ...                   ...  \n",
       "1329             0.008636              0.000706  \n",
       "1330             0.008889              0.003736  \n",
       "1331             0.008455              0.002959  \n",
       "1332             0.010154              0.001129  \n",
       "1333             0.007039              0.001615  \n",
       "\n",
       "[1334 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_B_X = train_B.drop(columns=['subjectivePoverty_rating'])\n",
    "# display(train_B_X)\n",
    "\n",
    "def predictratings_SVM(model, train_B_X):\n",
    "    test_ids = train_B_X['psu_hh_idcode']\n",
    "    # train_B_X = encoder(train_B_X)\n",
    "    # train_B_X = encode_filler(train_B_X)\n",
    "    preds_proba = model.predict_proba(train_B_X)\n",
    "    print(log_loss(train_B['subjectivePoverty_rating'], preds_proba))\n",
    "    output_df = pd.DataFrame(preds_proba, columns=[f'subjective_poverty{i+1}' for i in range(preds_proba.shape[1])])\n",
    "    output_df.insert(0, 'psu_hh_idcode', test_ids.values)  # Insert the ID column at the start\n",
    "    return output_df\n",
    "\n",
    "pred = predictratings_SVM(model, train_B_X)\n",
    "display(pred)\n",
    "\n",
    "#1.9505287965222604 - scale X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "psu_hh_idcode\tsubjective_poverty1\tsubjective_poverty2\tsubjective_poverty3\tsubjective_poverty4\tsubjective_poverty5\tsubjective_poverty6\tsubjective_poverty7\tsubjective_poverty8\tsubjective_poverty9\tsubjective_poverty10\n",
    "0\t125_11_1\t0.025525\t0.059814\t0.087623\t0.220639\t0.233748\t0.182541\t0.121753\t0.053184\t0.011969\t0.003203\n",
    "1\t129_9_1\t0.037075\t0.058612\t0.088723\t0.214832\t0.184983\t0.169812\t0.163631\t0.064149\t0.014398\t0.003784\n",
    "2\t800_8_1\t0.027463\t0.057546\t0.080168\t0.217410\t0.228223\t0.184984\t0.132869\t0.054868\t0.012673\t0.003796\n",
    "3\t472_1_1\t0.034906\t0.057764\t0.085594\t0.217024\t0.193675\t0.172937\t0.157929\t0.062606\t0.014007\t0.003559\n",
    "4\t309_11_1\t0.027289\t0.057630\t0.078263\t0.222137\t0.226802\t0.182085\t0.132389\t0.057131\t0.012434\t0.003839\n",
    "...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\n",
    "1329\t588_5_1\t0.026330\t0.058408\t0.083609\t0.219034\t0.233413\t0.183294\t0.125962\t0.054159\t0.012287\t0.003504\n",
    "1330\t566_4_1\t0.036910\t0.058539\t0.088463\t0.214998\t0.185711\t0.170098\t0.163133\t0.064025\t0.014363\t0.003761\n",
    "1331\t220_7_1\t0.031674\t0.057190\t0.081302\t0.220262\t0.208272\t0.177602\t0.146896\t0.059892\t0.013415\t0.003495\n",
    "1332\t144_5_2\t0.024264\t0.065964\t0.090802\t0.210098\t0.245841\t0.185363\t0.109233\t0.054836\t0.011278\t0.002322\n",
    "1333\t18_7_1\t0.034787\t0.057585\t0.085540\t0.217065\t0.194416\t0.173364\t0.157189\t0.062621\t0.013908\t0.003525\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
