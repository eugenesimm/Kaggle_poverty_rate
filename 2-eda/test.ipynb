{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import log_loss, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "MODEL_TRAINING_DATA_DIR = \"../data/model_training/\"\n",
    "CLEAN_DATA_DIR = \"../data/clean/\"\n",
    "RESULT_DATA_DIR = \"../data/model_result/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ratings_SVM(train_data):\n",
    "\n",
    "    train_x = train_data.drop(columns=['psu_hh_idcode', 'subjectivePoverty_rating'])\n",
    "    # # Combine numerical and encoded categorical data\n",
    "    # processed_train = encoder(train_x)\n",
    "    # processed_train = encode_filler(processed_train)\n",
    "\n",
    "    y = train_data['subjectivePoverty_rating']\n",
    "    # X = processed_train\n",
    "\n",
    "    ordinal_col = ['q23', 'Q06', 'Q01']\n",
    "    numerical_col = ['q05', 'q09', 'Q07']\n",
    "    binary_col =  ['q02', 'q03', 'Q03', 'Q08', 'Q11', 'Q19']\n",
    "\n",
    "    # Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', MinMaxScaler(), numerical_col),    # Scale numerical features\n",
    "            ('ord', MinMaxScaler(), ordinal_col),      # Scale ordinal categorical features\n",
    "            ('one_hot', 'passthrough', binary_col)      # Leave one-hot-encoded features unchanged\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Complete pipeline with SVM\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', SVC(probability=True, random_state=42))\n",
    "    ])\n",
    "    \n",
    "   # GridSearch CV\n",
    "    param_grid = {\n",
    "        'classifier__C': [0.1, 0.5, 1, 10],\n",
    "        'classifier__gamma': ['scale', 0.1, 0.01, 0.001],\n",
    "        'classifier__kernel': ['rbf']\n",
    "    }\n",
    "\n",
    "    optimal_params = GridSearchCV(pipeline, param_grid, n_jobs=-1, cv=5, scoring='neg_log_loss', verbose=1)\n",
    "    \n",
    "    # Fit the model\n",
    "    optimal_params.fit(train_x, y)\n",
    "    print(\"best score: \", optimal_params.best_score_)\n",
    "\n",
    "    #Save the results to csv file\n",
    "    results = optimal_params.cv_results_\n",
    "    log_loss_scores = results['mean_test_score']  # Mean log loss (negative)\n",
    "    hyperparameters = results['params'] \n",
    "    results_df = pd.DataFrame(hyperparameters)\n",
    "    results_df['Mean Log Loss'] = -log_loss_scores  # Convert back to positive (lower is better)\n",
    "\n",
    "    # Display the results sorted by Log Loss\n",
    "    results_df = results_df.sort_values(by='Mean Log Loss', ascending=True)\n",
    "    results_df.to_csv(os.path.join(RESULT_DATA_DIR, \"ecx_svm_pipeline_unfilled.csv\"), index=False)\n",
    "    return optimal_params.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['q02', 'q03', 'q05', 'q09', 'q23', 'Q01', 'Q03']\n",
    "['q02', 'q03', 'q05', 'q09', 'q23', 'Q01', 'Q03']\n",
    "['q02', 'q03', 'q05', 'q09', 'q23', 'Q01', 'Q03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "best score:  -1.9624797401918197\n"
     ]
    }
   ],
   "source": [
    "# train_data = pd.read_csv(os.path.join(MODEL_TRAINING_DATA_DIR, \"TRAIN_MERGED_UNFILLED_encoded.csv\"))\n",
    "train_data = pd.read_csv(os.path.join(CLEAN_DATA_DIR, \"TRAIN_MERGED_UNFILLED.csv\"))\n",
    "train_A, train_B = train_test_split(train_data, test_size=0.25, stratify=train_data['subjectivePoverty_rating'], random_state=42)\n",
    "model = predict_ratings_SVM(train_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictratings_SVM(model, train_B_X):\n",
    "    test_ids = train_B_X['psu_hh_idcode']\n",
    "    # train_B_X = encoder(train_B_X)\n",
    "    # train_B_X = encode_filler(train_B_X)\n",
    "    preds_proba = model.predict_proba(train_B_X)\n",
    "    print(log_loss(train_B['subjectivePoverty_rating'], preds_proba))\n",
    "    output_df = pd.DataFrame(preds_proba, columns=[f'subjective_poverty{i+1}' for i in range(preds_proba.shape[1])])\n",
    "    output_df.insert(0, 'psu_hh_idcode', test_ids.values)  # Insert the ID column at the start\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9575881303365301\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psu_hh_idcode</th>\n",
       "      <th>subjective_poverty1</th>\n",
       "      <th>subjective_poverty2</th>\n",
       "      <th>subjective_poverty3</th>\n",
       "      <th>subjective_poverty4</th>\n",
       "      <th>subjective_poverty5</th>\n",
       "      <th>subjective_poverty6</th>\n",
       "      <th>subjective_poverty7</th>\n",
       "      <th>subjective_poverty8</th>\n",
       "      <th>subjective_poverty9</th>\n",
       "      <th>subjective_poverty10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125_11_1</td>\n",
       "      <td>0.039290</td>\n",
       "      <td>0.091817</td>\n",
       "      <td>0.178437</td>\n",
       "      <td>0.214899</td>\n",
       "      <td>0.209453</td>\n",
       "      <td>0.143429</td>\n",
       "      <td>0.078440</td>\n",
       "      <td>0.034249</td>\n",
       "      <td>0.008007</td>\n",
       "      <td>0.001979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129_9_1</td>\n",
       "      <td>0.035739</td>\n",
       "      <td>0.091321</td>\n",
       "      <td>0.171501</td>\n",
       "      <td>0.214516</td>\n",
       "      <td>0.209784</td>\n",
       "      <td>0.151591</td>\n",
       "      <td>0.076997</td>\n",
       "      <td>0.037985</td>\n",
       "      <td>0.008212</td>\n",
       "      <td>0.002354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>800_8_1</td>\n",
       "      <td>0.035694</td>\n",
       "      <td>0.072921</td>\n",
       "      <td>0.165916</td>\n",
       "      <td>0.213400</td>\n",
       "      <td>0.209383</td>\n",
       "      <td>0.154384</td>\n",
       "      <td>0.090034</td>\n",
       "      <td>0.047295</td>\n",
       "      <td>0.009538</td>\n",
       "      <td>0.001436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>472_1_1</td>\n",
       "      <td>0.029825</td>\n",
       "      <td>0.063753</td>\n",
       "      <td>0.094181</td>\n",
       "      <td>0.191058</td>\n",
       "      <td>0.222054</td>\n",
       "      <td>0.199455</td>\n",
       "      <td>0.116729</td>\n",
       "      <td>0.066007</td>\n",
       "      <td>0.012675</td>\n",
       "      <td>0.004265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>309_11_1</td>\n",
       "      <td>0.038018</td>\n",
       "      <td>0.088696</td>\n",
       "      <td>0.170608</td>\n",
       "      <td>0.210838</td>\n",
       "      <td>0.209003</td>\n",
       "      <td>0.147142</td>\n",
       "      <td>0.085202</td>\n",
       "      <td>0.041189</td>\n",
       "      <td>0.007888</td>\n",
       "      <td>0.001415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>588_5_1</td>\n",
       "      <td>0.040227</td>\n",
       "      <td>0.087402</td>\n",
       "      <td>0.175998</td>\n",
       "      <td>0.214224</td>\n",
       "      <td>0.206970</td>\n",
       "      <td>0.143691</td>\n",
       "      <td>0.084469</td>\n",
       "      <td>0.037193</td>\n",
       "      <td>0.008532</td>\n",
       "      <td>0.001293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>566_4_1</td>\n",
       "      <td>0.036206</td>\n",
       "      <td>0.089240</td>\n",
       "      <td>0.172897</td>\n",
       "      <td>0.211116</td>\n",
       "      <td>0.204938</td>\n",
       "      <td>0.150938</td>\n",
       "      <td>0.082090</td>\n",
       "      <td>0.041067</td>\n",
       "      <td>0.009077</td>\n",
       "      <td>0.002431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>220_7_1</td>\n",
       "      <td>0.037429</td>\n",
       "      <td>0.088212</td>\n",
       "      <td>0.164148</td>\n",
       "      <td>0.207216</td>\n",
       "      <td>0.208730</td>\n",
       "      <td>0.154948</td>\n",
       "      <td>0.086079</td>\n",
       "      <td>0.042369</td>\n",
       "      <td>0.008590</td>\n",
       "      <td>0.002279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>144_5_2</td>\n",
       "      <td>0.051523</td>\n",
       "      <td>0.058908</td>\n",
       "      <td>0.084303</td>\n",
       "      <td>0.157352</td>\n",
       "      <td>0.211073</td>\n",
       "      <td>0.191334</td>\n",
       "      <td>0.152542</td>\n",
       "      <td>0.076725</td>\n",
       "      <td>0.013287</td>\n",
       "      <td>0.002954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>18_7_1</td>\n",
       "      <td>0.035316</td>\n",
       "      <td>0.088679</td>\n",
       "      <td>0.179072</td>\n",
       "      <td>0.212915</td>\n",
       "      <td>0.206842</td>\n",
       "      <td>0.141807</td>\n",
       "      <td>0.083793</td>\n",
       "      <td>0.041709</td>\n",
       "      <td>0.008121</td>\n",
       "      <td>0.001748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1334 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     psu_hh_idcode  subjective_poverty1  subjective_poverty2  \\\n",
       "0         125_11_1             0.039290             0.091817   \n",
       "1          129_9_1             0.035739             0.091321   \n",
       "2          800_8_1             0.035694             0.072921   \n",
       "3          472_1_1             0.029825             0.063753   \n",
       "4         309_11_1             0.038018             0.088696   \n",
       "...            ...                  ...                  ...   \n",
       "1329       588_5_1             0.040227             0.087402   \n",
       "1330       566_4_1             0.036206             0.089240   \n",
       "1331       220_7_1             0.037429             0.088212   \n",
       "1332       144_5_2             0.051523             0.058908   \n",
       "1333        18_7_1             0.035316             0.088679   \n",
       "\n",
       "      subjective_poverty3  subjective_poverty4  subjective_poverty5  \\\n",
       "0                0.178437             0.214899             0.209453   \n",
       "1                0.171501             0.214516             0.209784   \n",
       "2                0.165916             0.213400             0.209383   \n",
       "3                0.094181             0.191058             0.222054   \n",
       "4                0.170608             0.210838             0.209003   \n",
       "...                   ...                  ...                  ...   \n",
       "1329             0.175998             0.214224             0.206970   \n",
       "1330             0.172897             0.211116             0.204938   \n",
       "1331             0.164148             0.207216             0.208730   \n",
       "1332             0.084303             0.157352             0.211073   \n",
       "1333             0.179072             0.212915             0.206842   \n",
       "\n",
       "      subjective_poverty6  subjective_poverty7  subjective_poverty8  \\\n",
       "0                0.143429             0.078440             0.034249   \n",
       "1                0.151591             0.076997             0.037985   \n",
       "2                0.154384             0.090034             0.047295   \n",
       "3                0.199455             0.116729             0.066007   \n",
       "4                0.147142             0.085202             0.041189   \n",
       "...                   ...                  ...                  ...   \n",
       "1329             0.143691             0.084469             0.037193   \n",
       "1330             0.150938             0.082090             0.041067   \n",
       "1331             0.154948             0.086079             0.042369   \n",
       "1332             0.191334             0.152542             0.076725   \n",
       "1333             0.141807             0.083793             0.041709   \n",
       "\n",
       "      subjective_poverty9  subjective_poverty10  \n",
       "0                0.008007              0.001979  \n",
       "1                0.008212              0.002354  \n",
       "2                0.009538              0.001436  \n",
       "3                0.012675              0.004265  \n",
       "4                0.007888              0.001415  \n",
       "...                   ...                   ...  \n",
       "1329             0.008532              0.001293  \n",
       "1330             0.009077              0.002431  \n",
       "1331             0.008590              0.002279  \n",
       "1332             0.013287              0.002954  \n",
       "1333             0.008121              0.001748  \n",
       "\n",
       "[1334 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_B_X = train_B.drop(columns=['subjectivePoverty_rating'])\n",
    "pred = predictratings_SVM(model, train_B_X)\n",
    "display(pred)\n",
    "#1.9505287965222604 - pipeline X, encoded X\n",
    "#1.9847676398932983 - pipeline X, encoded 0\n",
    "#1.9525670441687637 - pipeline 0 , encoded 0 1.953911477755434\n",
    "#1.9533630140413745 - pipeline 0 , encoded X\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
